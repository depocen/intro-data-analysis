<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>16.3 Selected tests | Introduction to Data Analysis</title>
  <meta name="description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content="16.3 Selected tests | Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="16.3 Selected tests | Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Introductory text for statistics and data analysis (using R)" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-03-05-hypothesis-testing-CLT.html"/>
<link rel="next" href="ch-03-05-hypothesis-testing-3-approaches.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!--<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.css">-->
<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.css">

<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-v0.9.13.js" defer async></script>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />

<script type="application/javascript">
document.addEventListener('DOMContentLoaded', function() {
  document.querySelectorAll('.collapsibleSolution, .collapsibleProof').forEach(function(collapsible) {
    const content = collapsible.querySelector('.content')
    content.style.display = 'none';
    collapsible.querySelector('.trigger').addEventListener('click', function() {
      if (content.style.display === 'none') {
        content.style.display = 'block';
      } else {
        content.style.display = 'none';
      }
    })
  })
})
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>


<link rel="stylesheet" href="styles.css" type="text/css" />
<link rel="stylesheet" href="webppl-editor.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="Chap-01-00-intro-learning-goals.html"><a href="Chap-01-00-intro-learning-goals.html"><i class="fa fa-check"></i><b>1.1</b> Learning goals</a></li>
<li class="chapter" data-level="1.2" data-path="Chap-01-00-intro-course-structure.html"><a href="Chap-01-00-intro-course-structure.html"><i class="fa fa-check"></i><b>1.2</b> Course structure</a></li>
<li class="chapter" data-level="1.3" data-path="Chap-01-00-intro-tools.html"><a href="Chap-01-00-intro-tools.html"><i class="fa fa-check"></i><b>1.3</b> Tools used in this course</a></li>
<li class="chapter" data-level="1.4" data-path="Chap-01-00-intro-topics.html"><a href="Chap-01-00-intro-topics.html"><i class="fa fa-check"></i><b>1.4</b> Topics covered (and not covered) in the course</a></li>
<li class="chapter" data-level="1.5" data-path="Chap-01-00-intro-data-sets.html"><a href="Chap-01-00-intro-data-sets.html"><i class="fa fa-check"></i><b>1.5</b> Data sets covered</a></li>
<li class="chapter" data-level="1.6" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html"><i class="fa fa-check"></i><b>1.6</b> Installation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap-01-01-R.html"><a href="Chap-01-01-R.html"><i class="fa fa-check"></i><b>2</b> Basics of R</a><ul>
<li class="chapter" data-level="2.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>2.1</b> First steps</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#functions"><i class="fa fa-check"></i><b>2.1.1</b> Functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>2.1.2</b> Variables</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>2.1.3</b> Literate coding</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>2.1.4</b> Objects</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#packages"><i class="fa fa-check"></i><b>2.1.5</b> Packages</a></li>
<li class="chapter" data-level="2.1.6" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#Chap-01-01-R-help"><i class="fa fa-check"></i><b>2.1.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>2.2</b> Data types</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numeric-vectors-matrices"><i class="fa fa-check"></i><b>2.2.1</b> Numeric vectors &amp; matrices</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>2.2.2</b> Booleans</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>2.2.3</b> Special values</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>2.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>2.2.5</b> Factors</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>2.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html"><i class="fa fa-check"></i><b>2.3</b> Functions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#some-important-built-in-functions"><i class="fa fa-check"></i><b>2.3.1</b> Some important built-in functions</a></li>
<li class="chapter" data-level="2.3.2" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#defining-your-own-functions"><i class="fa fa-check"></i><b>2.3.2</b> Defining your own functions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html"><i class="fa fa-check"></i><b>2.4</b> Loops and maps</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#for-loops"><i class="fa fa-check"></i><b>2.4.1</b> For-loops</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#functional-iterators"><i class="fa fa-check"></i><b>2.4.2</b> Functional iterators</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html"><i class="fa fa-check"></i><b>2.5</b> Piping</a></li>
<li class="chapter" data-level="2.6" data-path="ch-01-01-Rmarkdown.html"><a href="ch-01-01-Rmarkdown.html"><i class="fa fa-check"></i><b>2.6</b> Rmarkdown</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="3" data-path="Chap-02-01-data.html"><a href="Chap-02-01-data.html"><i class="fa fa-check"></i><b>3</b> Data, variables &amp; experimental designs</a><ul>
<li class="chapter" data-level="3.1" data-path="Chap-02-01-data-what-is-data.html"><a href="Chap-02-01-data-what-is-data.html"><i class="fa fa-check"></i><b>3.1</b> What is data?</a></li>
<li class="chapter" data-level="3.2" data-path="Chap-02-01-data-kinds-of-data.html"><a href="Chap-02-01-data-kinds-of-data.html"><i class="fa fa-check"></i><b>3.2</b> Different kinds of data</a></li>
<li class="chapter" data-level="3.3" data-path="Chap-02-01-data-variables.html"><a href="Chap-02-01-data-variables.html"><i class="fa fa-check"></i><b>3.3</b> On the notion of “variables”</a></li>
<li class="chapter" data-level="3.4" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html"><i class="fa fa-check"></i><b>3.4</b> Basics of experimental design</a><ul>
<li class="chapter" data-level="3.4.1" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#what-to-analyze-dependent-variables"><i class="fa fa-check"></i><b>3.4.1</b> What to analyze? – Dependent variables</a></li>
<li class="chapter" data-level="3.4.2" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#conditions-trials-items"><i class="fa fa-check"></i><b>3.4.2</b> Conditions, trials, items</a></li>
<li class="chapter" data-level="3.4.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#sample-size"><i class="fa fa-check"></i><b>3.4.3</b> Sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="Chap-02-02-data-IO.html"><a href="Chap-02-02-data-IO.html"><i class="fa fa-check"></i><b>4.1</b> Data in, data out</a></li>
<li class="chapter" data-level="4.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#running-example"><i class="fa fa-check"></i><b>4.2.1</b> Running example</a></li>
<li class="chapter" data-level="4.2.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>4.2.2</b> Definition of <em>tidy data</em></a></li>
<li class="chapter" data-level="4.2.3" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#excursion-non-redundant-data"><i class="fa fa-check"></i><b>4.2.3</b> Excursion: non-redundant data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html"><i class="fa fa-check"></i><b>4.3</b> Data manipulation: the basics</a><ul>
<li class="chapter" data-level="4.3.1" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#pivoting"><i class="fa fa-check"></i><b>4.3.1</b> Pivoting</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#subsetting-row-columns"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting row &amp; columns</a></li>
<li class="chapter" data-level="4.3.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#Chap-02-02-tidy-selection"><i class="fa fa-check"></i><b>4.3.3</b> Tidy selection of column names</a></li>
<li class="chapter" data-level="4.3.4" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#adding-changing-and-renaming-columns"><i class="fa fa-check"></i><b>4.3.4</b> Adding, changing and renaming columns</a></li>
<li class="chapter" data-level="4.3.5" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#splitting-and-uniting-columns"><i class="fa fa-check"></i><b>4.3.5</b> Splitting and uniting columns</a></li>
<li class="chapter" data-level="4.3.6" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#sorting-a-data-set"><i class="fa fa-check"></i><b>4.3.6</b> Sorting a data set</a></li>
<li class="chapter" data-level="4.3.7" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#combining-tibbles"><i class="fa fa-check"></i><b>4.3.7</b> Combining tibbles</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chap-02-02-data-grouping-nesting.html"><a href="Chap-02-02-data-grouping-nesting.html"><i class="fa fa-check"></i><b>4.4</b> Grouped operations</a></li>
<li class="chapter" data-level="4.5" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html"><i class="fa fa-check"></i><b>4.5</b> Case study: the King of France</a><ul>
<li class="chapter" data-level="4.5.1" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html#cleaning-the-data"><i class="fa fa-check"></i><b>4.5.1</b> Cleaning the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap-02-03-summary-statistics.html"><a href="Chap-02-03-summary-statistics.html"><i class="fa fa-check"></i><b>5</b> Summary statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html"><i class="fa fa-check"></i><b>5.1</b> Counts and proportions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#loading-and-inspecting-the-data"><i class="fa fa-check"></i><b>5.1.1</b> Loading and inspecting the data</a></li>
<li class="chapter" data-level="5.1.2" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#obtaining-counts-with-n-count-and-tally"><i class="fa fa-check"></i><b>5.1.2</b> Obtaining counts with <code>n</code>, <code>count</code> and <code>tally</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html"><i class="fa fa-check"></i><b>5.2</b> Central tendency and dispersion</a><ul>
<li class="chapter" data-level="5.2.1" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#the-data-for-the-remainder-of-the-chapter"><i class="fa fa-check"></i><b>5.2.1</b> The data for the remainder of the chapter</a></li>
<li class="chapter" data-level="5.2.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.2.2</b> Measures of central tendency</a></li>
<li class="chapter" data-level="5.2.3" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-dispersion"><i class="fa fa-check"></i><b>5.2.3</b> Measures of dispersion</a></li>
<li class="chapter" data-level="5.2.4" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#excursion-quantifying-confidence-with-bootstrapping"><i class="fa fa-check"></i><b>5.2.4</b> Excursion: Quantifying confidence with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html"><i class="fa fa-check"></i><b>5.3</b> Covariance and correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#covariance"><i class="fa fa-check"></i><b>5.3.1</b> Covariance</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#correlation"><i class="fa fa-check"></i><b>5.3.2</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap-02-02-visualization.html"><a href="Chap-02-02-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="Chap-02-04-Anscombe-example.html"><a href="Chap-02-04-Anscombe-example.html"><i class="fa fa-check"></i><b>6.1</b> Motivating example: Anscombe’s quartet</a></li>
<li class="chapter" data-level="6.2" data-path="Chap-02-04-good-visualization.html"><a href="Chap-02-04-good-visualization.html"><i class="fa fa-check"></i><b>6.2</b> Visualization: the good, the bad and the infographic</a></li>
<li class="chapter" data-level="6.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html"><i class="fa fa-check"></i><b>6.3</b> Basics of <code>ggplot</code></a><ul>
<li class="chapter" data-level="6.3.1" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#incremental-composition-of-a-plot"><i class="fa fa-check"></i><b>6.3.1</b> Incremental composition of a plot</a></li>
<li class="chapter" data-level="6.3.2" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#elements-in-the-layered-grammar-of-graphs"><i class="fa fa-check"></i><b>6.3.2</b> Elements in the layered grammar of graphs</a></li>
<li class="chapter" data-level="6.3.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#layers-and-groups"><i class="fa fa-check"></i><b>6.3.3</b> Layers and groups</a></li>
<li class="chapter" data-level="6.3.4" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#grouping"><i class="fa fa-check"></i><b>6.3.4</b> Grouping</a></li>
<li class="chapter" data-level="6.3.5" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#example-of-a-customized-plot"><i class="fa fa-check"></i><b>6.3.5</b> Example of a customized plot</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html"><i class="fa fa-check"></i><b>6.4</b> A rendezvous with popular geoms</a><ul>
<li class="chapter" data-level="6.4.1" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#scatter-plots-with-geom_point"><i class="fa fa-check"></i><b>6.4.1</b> Scatter plots with <code>geom_point</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#smooth"><i class="fa fa-check"></i><b>6.4.2</b> Smooth</a></li>
<li class="chapter" data-level="6.4.3" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#line"><i class="fa fa-check"></i><b>6.4.3</b> Line</a></li>
<li class="chapter" data-level="6.4.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#barplot"><i class="fa fa-check"></i><b>6.4.4</b> Barplot</a></li>
<li class="chapter" data-level="6.4.5" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#plotting-distributions-histograms-boxplots-densities-and-violins"><i class="fa fa-check"></i><b>6.4.5</b> Plotting distributions: histograms, boxplots, densities and violins</a></li>
<li class="chapter" data-level="6.4.6" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#rugs"><i class="fa fa-check"></i><b>6.4.6</b> Rugs</a></li>
<li class="chapter" data-level="6.4.7" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#annotation"><i class="fa fa-check"></i><b>6.4.7</b> Annotation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Chap-02-04-faceting.html"><a href="Chap-02-04-faceting.html"><i class="fa fa-check"></i><b>6.5</b> Faceting</a></li>
<li class="chapter" data-level="6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html"><i class="fa fa-check"></i><b>6.6</b> Customization etc.</a><ul>
<li class="chapter" data-level="6.6.1" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#themes"><i class="fa fa-check"></i><b>6.6.1</b> Themes</a></li>
<li class="chapter" data-level="6.6.2" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#guides"><i class="fa fa-check"></i><b>6.6.2</b> Guides</a></li>
<li class="chapter" data-level="6.6.3" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#axes-ticks-and-tick-labels"><i class="fa fa-check"></i><b>6.6.3</b> Axes, ticks and tick labels</a></li>
<li class="chapter" data-level="6.6.4" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#labels"><i class="fa fa-check"></i><b>6.6.4</b> Labels</a></li>
<li class="chapter" data-level="6.6.5" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#combining-arranging-plots"><i class="fa fa-check"></i><b>6.6.5</b> Combining &amp; arranging plots</a></li>
<li class="chapter" data-level="6.6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#latex-expressions-in-plot-labels"><i class="fa fa-check"></i><b>6.6.6</b> LaTeX expressions in plot labels</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Bayesian Data Analysis</b></span></li>
<li class="chapter" data-level="7" data-path="Chap-03-01-probability.html"><a href="Chap-03-01-probability.html"><i class="fa fa-check"></i><b>7</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="7.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html"><i class="fa fa-check"></i><b>7.1</b> Probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#outcomes-events-observations"><i class="fa fa-check"></i><b>7.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="7.1.2" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.3" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#interpretations-of-probability"><i class="fa fa-check"></i><b>7.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="7.1.4" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#distributions-as-samples"><i class="fa fa-check"></i><b>7.1.4</b> Distributions as samples</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html"><i class="fa fa-check"></i><b>7.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#probability-table-for-a-flip-and-draw-scenario"><i class="fa fa-check"></i><b>7.2.1</b> Probability table for a flip-and-draw scenario</a></li>
<li class="chapter" data-level="7.2.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>7.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="7.2.3" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#marginalization"><i class="fa fa-check"></i><b>7.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html"><i class="fa fa-check"></i><b>7.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="7.3.1" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#bayes-rule"><i class="fa fa-check"></i><b>7.3.1</b> Bayes rule</a></li>
<li class="chapter" data-level="7.3.2" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence"><i class="fa fa-check"></i><b>7.3.2</b> Stochastic (in-)dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html"><i class="fa fa-check"></i><b>7.4</b> Random variables</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>7.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="7.4.2" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>7.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
<li class="chapter" data-level="7.4.3" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#expected-value-variance"><i class="fa fa-check"></i><b>7.4.3</b> Expected value &amp; variance</a></li>
<li class="chapter" data-level="7.4.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#composite-random-variables"><i class="fa fa-check"></i><b>7.4.4</b> Composite random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Chap-03-01-probability-R.html"><a href="Chap-03-01-probability-R.html"><i class="fa fa-check"></i><b>7.5</b> Probability distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap-03-03-models.html"><a href="Chap-03-03-models.html"><i class="fa fa-check"></i><b>8</b> Statistical models</a><ul>
<li class="chapter" data-level="8.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html"><i class="fa fa-check"></i><b>8.1</b> Statistical models</a></li>
<li class="chapter" data-level="8.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html"><i class="fa fa-check"></i><b>8.2</b> Notation &amp; graphical representation</a><ul>
<li class="chapter" data-level="8.2.1" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#formula-notation"><i class="fa fa-check"></i><b>8.2.1</b> Formula notation</a></li>
<li class="chapter" data-level="8.2.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#graphical-notation"><i class="fa fa-check"></i><b>8.2.2</b> Graphical notation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html"><i class="fa fa-check"></i><b>8.3</b> Parameters, priors, and prior predictions</a><ul>
<li class="chapter" data-level="8.3.1" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#whats-a-model-parameter"><i class="fa fa-check"></i><b>8.3.1</b> What’s a model parameter?</a></li>
<li class="chapter" data-level="8.3.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-02-models-priors"><i class="fa fa-check"></i><b>8.3.2</b> Priors over parameters</a></li>
<li class="chapter" data-level="8.3.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-03-models-parameters-prior-predictive"><i class="fa fa-check"></i><b>8.3.3</b> Prior predictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-03-04-parameter-estimation.html"><a href="ch-03-04-parameter-estimation.html"><i class="fa fa-check"></i><b>9</b> Bayesian parameter estimation</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html"><i class="fa fa-check"></i><b>9.1</b> Bayes rule for parameter estimation</a><ul>
<li class="chapter" data-level="9.1.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#definitions-and-terminology"><i class="fa fa-check"></i><b>9.1.1</b> Definitions and terminology</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#the-effects-of-prior-and-likelihood-on-the-posterior"><i class="fa fa-check"></i><b>9.1.2</b> The effects of prior and likelihood on the posterior</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#ch-03-04-parameter-estimation-conjugacy"><i class="fa fa-check"></i><b>9.1.3</b> Computing Bayesian posteriors with conjugate priors</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#excursion-sequential-updating"><i class="fa fa-check"></i><b>9.1.4</b> Excursion: Sequential updating</a></li>
<li class="chapter" data-level="9.1.5" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>9.1.5</b> Posterior predictive distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html"><i class="fa fa-check"></i><b>9.2</b> Point-valued and interval-ranged estimates</a><ul>
<li class="chapter" data-level="9.2.1" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#point-valued-estimates"><i class="fa fa-check"></i><b>9.2.1</b> Point-valued estimates</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#interval-ranged-estimates"><i class="fa fa-check"></i><b>9.2.2</b> Interval-ranged estimates</a></li>
<li class="chapter" data-level="9.2.3" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#computing-bayesian-estimates"><i class="fa fa-check"></i><b>9.2.3</b> Computing Bayesian estimates</a></li>
<li class="chapter" data-level="9.2.4" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#excursion-computing-mles-and-maps-in-r"><i class="fa fa-check"></i><b>9.2.4</b> Excursion: Computing MLEs and MAPs in R</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html"><i class="fa fa-check"></i><b>9.3</b> Approximating the posterior</a><ul>
<li class="chapter" data-level="9.3.1" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-MCMC"><i class="fa fa-check"></i><b>9.3.1</b> Of apples and trees: Markov Chain Monte Carlo sampling</a></li>
<li class="chapter" data-level="9.3.2" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-estimation-Stan"><i class="fa fa-check"></i><b>9.3.2</b> Excursion: Probabilistic modeling with Stan</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html"><i class="fa fa-check"></i><b>9.4</b> Estimating the parameters of a Normal distribution</a><ul>
<li class="chapter" data-level="9.4.1" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#uninformative-priors"><i class="fa fa-check"></i><b>9.4.1</b> Uninformative priors</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#conjugate-priors"><i class="fa fa-check"></i><b>9.4.2</b> Conjugate priors</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#estimating-the-difference-between-group-means"><i class="fa fa-check"></i><b>9.4.3</b> Estimating the difference between group means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap-03-06-model-comparison.html"><a href="Chap-03-06-model-comparison.html"><i class="fa fa-check"></i><b>10</b> Model Comparison</a><ul>
<li class="chapter" data-level="10.1" data-path="Chap-03-06-model-comparison-case-study.html"><a href="Chap-03-06-model-comparison-case-study.html"><i class="fa fa-check"></i><b>10.1</b> Case study: recall models</a></li>
<li class="chapter" data-level="10.2" data-path="Chap-03-06-model-comparison-AIC.html"><a href="Chap-03-06-model-comparison-AIC.html"><i class="fa fa-check"></i><b>10.2</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="10.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html"><i class="fa fa-check"></i><b>10.3</b> Bayes factors</a><ul>
<li class="chapter" data-level="10.3.1" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-grid"><i class="fa fa-check"></i><b>10.3.1</b> Grid approximation</a></li>
<li class="chapter" data-level="10.3.2" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-naiveMC"><i class="fa fa-check"></i><b>10.3.2</b> Naive Monte Carlo</a></li>
<li class="chapter" data-level="10.3.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-grid"><i class="fa fa-check"></i><b>10.3.3</b> Excursion: Bridge sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-03-07-hypothesis-testing-Bayes.html"><a href="ch-03-07-hypothesis-testing-Bayes.html"><i class="fa fa-check"></i><b>11</b> Bayesian hypothesis testing</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><a href="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><i class="fa fa-check"></i><b>11.1</b> Statistical hypotheses</a></li>
<li class="chapter" data-level="11.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html"><i class="fa fa-check"></i><b>11.2</b> Data and models for this chapter</a><ul>
<li class="chapter" data-level="11.2.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#section"><i class="fa fa-check"></i><b>11.2.1</b> 24/7</a></li>
<li class="chapter" data-level="11.2.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#simon-task"><i class="fa fa-check"></i><b>11.2.2</b> Simon task</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html"><i class="fa fa-check"></i><b>11.3</b> Testing via posterior estimation</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-247"><i class="fa fa-check"></i><b>11.3.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-simon-task"><i class="fa fa-check"></i><b>11.3.2</b> Example: Simon Task</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html"><i class="fa fa-check"></i><b>11.4</b> Testing via model comparison</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey"><i class="fa fa-check"></i><b>11.4.1</b> The Savage-Dickey method</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models"><i class="fa fa-check"></i><b>11.4.2</b> Encompassing models</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Applied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="12" data-path="Chap-04-01-simple-linear-regression.html"><a href="Chap-04-01-simple-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Linear regression</a><ul>
<li class="chapter" data-level="12.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html"><i class="fa fa-check"></i><b>12.1</b> Ordinary least squares regression</a><ul>
<li class="chapter" data-level="12.1.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-without-any-further-information"><i class="fa fa-check"></i><b>12.1.1</b> Prediction without any further information</a></li>
<li class="chapter" data-level="12.1.2" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-with-knowledge-of-unemployment-rate"><i class="fa fa-check"></i><b>12.1.2</b> Prediction with knowledge of unemployment rate</a></li>
<li class="chapter" data-level="12.1.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#linear-regression-general-problem-formulation"><i class="fa fa-check"></i><b>12.1.3</b> Linear regression: general problem formulation</a></li>
<li class="chapter" data-level="12.1.4" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#finding-the-ols-solution"><i class="fa fa-check"></i><b>12.1.4</b> Finding the OLS-solution</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html"><i class="fa fa-check"></i><b>12.2</b> A maximum-likelihood approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#a-likelihood-based-model"><i class="fa fa-check"></i><b>12.2.1</b> A likelihood-based model</a></li>
<li class="chapter" data-level="12.2.2" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-optim"><i class="fa fa-check"></i><b>12.2.2</b> Finding the MLE-solution with <code>optim</code></a></li>
<li class="chapter" data-level="12.2.3" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-glm"><i class="fa fa-check"></i><b>12.2.3</b> Finding the MLE-solution with <code>glm</code></a></li>
<li class="chapter" data-level="12.2.4" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-math"><i class="fa fa-check"></i><b>12.2.4</b> Finding the MLE-solution with math</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html"><i class="fa fa-check"></i><b>12.3</b> A Bayesian approach</a></li>
<li class="chapter" data-level="12.4" data-path="comparison-of-approaches.html"><a href="comparison-of-approaches.html"><i class="fa fa-check"></i><b>12.4</b> Comparison of approaches</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap-04-02-Bayes-regression-practice.html"><a href="Chap-04-02-Bayes-regression-practice.html"><i class="fa fa-check"></i><b>13</b> Bayesian regression in practice</a><ul>
<li class="chapter" data-level="13.1" data-path="simple-linear-regression-with-brms.html"><a href="simple-linear-regression-with-brms.html"><i class="fa fa-check"></i><b>13.1</b> Simple linear regression with <code>brms</code></a></li>
<li class="chapter" data-level="13.2" data-path="extracting-posterior-samples.html"><a href="extracting-posterior-samples.html"><i class="fa fa-check"></i><b>13.2</b> Extracting posterior samples</a></li>
<li class="chapter" data-level="13.3" data-path="excursion-inspecting-the-underlying-stan-code.html"><a href="excursion-inspecting-the-underlying-stan-code.html"><i class="fa fa-check"></i><b>13.3</b> [Excursion:] Inspecting the underlying Stan code</a></li>
<li class="chapter" data-level="13.4" data-path="setting-priors.html"><a href="setting-priors.html"><i class="fa fa-check"></i><b>13.4</b> Setting priors</a></li>
<li class="chapter" data-level="13.5" data-path="posterior-predictions.html"><a href="posterior-predictions.html"><i class="fa fa-check"></i><b>13.5</b> Posterior predictions</a></li>
<li class="chapter" data-level="13.6" data-path="testing-hypotheses.html"><a href="testing-hypotheses.html"><i class="fa fa-check"></i><b>13.6</b> Testing hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap-04-03-predictors.html"><a href="Chap-04-03-predictors.html"><i class="fa fa-check"></i><b>14</b> Categorical predictors</a><ul>
<li class="chapter" data-level="14.1" data-path="Chap-04-03-predictors-two-levels.html"><a href="Chap-04-03-predictors-two-levels.html"><i class="fa fa-check"></i><b>14.1</b> Single two-level predictor</a></li>
<li class="chapter" data-level="14.2" data-path="Chap-04-03-predictors-multi-levels.html"><a href="Chap-04-03-predictors-multi-levels.html"><i class="fa fa-check"></i><b>14.2</b> Single multi-level predictors</a></li>
<li class="chapter" data-level="14.3" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html"><i class="fa fa-check"></i><b>14.3</b> Multiple predictors</a><ul>
<li class="chapter" data-level="14.3.1" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html#treatment-coding"><i class="fa fa-check"></i><b>14.3.1</b> Treatment coding</a></li>
<li class="chapter" data-level="14.3.2" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html#sum-coding"><i class="fa fa-check"></i><b>14.3.2</b> Sum coding</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="Chap-04-04-GLM.html"><a href="Chap-04-04-GLM.html"><i class="fa fa-check"></i><b>15</b> Generalized linear model</a><ul>
<li class="chapter" data-level="15.1" data-path="generalizing-the-linear-regression-model.html"><a href="generalizing-the-linear-regression-model.html"><i class="fa fa-check"></i><b>15.1</b> Generalizing the linear regression model</a></li>
<li class="chapter" data-level="15.2" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>15.2</b> Logistic regression</a></li>
</ul></li>
<li class="part"><span><b>V Frequentist statistics</b></span></li>
<li class="chapter" data-level="16" data-path="ch-05-01-frequentist-hypothesis-testing.html"><a href="ch-05-01-frequentist-hypothesis-testing.html"><i class="fa fa-check"></i><b>16</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="16.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html"><i class="fa fa-check"></i><b>16.1</b> <em>p</em>-values</a><ul>
<li class="chapter" data-level="16.1.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#binomial-model---frequentist-version"><i class="fa fa-check"></i><b>16.1.1</b> Binomial Model - frequentist version</a></li>
<li class="chapter" data-level="16.1.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-for-the-binomial-model"><i class="fa fa-check"></i><b>16.1.2</b> <em>p</em>-values for the Binomial Model</a></li>
<li class="chapter" data-level="16.1.3" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#statistical-significance"><i class="fa fa-check"></i><b>16.1.3</b> Statistical significance</a></li>
<li class="chapter" data-level="16.1.4" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-and-alpha-errors"><i class="fa fa-check"></i><b>16.1.4</b> <em>p</em>-values and <span class="math inline">\(\alpha\)</span>-errors</a></li>
<li class="chapter" data-level="16.1.5" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#relation-of-p-values-to-confidence-intervals"><i class="fa fa-check"></i><b>16.1.5</b> Relation of <em>p</em>-values to confidence intervals</a></li>
<li class="chapter" data-level="16.1.6" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#distribution-of-p-values"><i class="fa fa-check"></i><b>16.1.6</b> Distribution of <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="16.1.7" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#how-not-to-interpret-p-values"><i class="fa fa-check"></i><b>16.1.7</b> How (not) to interpret <em>p</em>-values</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html"><i class="fa fa-check"></i><b>16.2</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="16.2.1" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html#hands-on"><i class="fa fa-check"></i><b>16.2.1</b> Hands-on</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html"><i class="fa fa-check"></i><b>16.3</b> Selected tests</a><ul>
<li class="chapter" data-level="16.3.1" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-Pearsons-Chi"><i class="fa fa-check"></i><b>16.3.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span>-tests</a></li>
<li class="chapter" data-level="16.3.2" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-z-test"><i class="fa fa-check"></i><b>16.3.2</b> <em>z</em>-test</a></li>
<li class="chapter" data-level="16.3.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-t-test"><i class="fa fa-check"></i><b>16.3.3</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="16.3.4" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-ANOVA"><i class="fa fa-check"></i><b>16.3.4</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html"><i class="fa fa-check"></i><b>16.4</b> Three approaches</a><ul>
<li class="chapter" data-level="16.4.1" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#fisher"><i class="fa fa-check"></i><b>16.4.1</b> Fisher</a></li>
<li class="chapter" data-level="16.4.2" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#neyman-pearson"><i class="fa fa-check"></i><b>16.4.2</b> Neyman-Pearson</a></li>
<li class="chapter" data-level="16.4.3" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#hybrid-modern-nhst"><i class="fa fa-check"></i><b>16.4.3</b> Hybrid modern NHST</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="ch-03-05-hypothesis-testing-3-model-checking.html"><a href="ch-03-05-hypothesis-testing-3-model-checking.html"><i class="fa fa-check"></i><b>16.5</b> Relation to model checking</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="app-90-further-material.html"><a href="app-90-further-material.html"><i class="fa fa-check"></i><b>A</b> Further useful material</a><ul>
<li class="chapter" data-level="A.1" data-path="material-on-introduction-to-probability.html"><a href="material-on-introduction-to-probability.html"><i class="fa fa-check"></i><b>A.1</b> Material on <em>Introduction to Probability</em>:</a></li>
<li class="chapter" data-level="A.2" data-path="material-on-bayesian-data-analysis.html"><a href="material-on-bayesian-data-analysis.html"><i class="fa fa-check"></i><b>A.2</b> Material on <em>Bayesian Data Analysis</em>:</a></li>
<li class="chapter" data-level="A.3" data-path="material-on-frequentist-statistics.html"><a href="material-on-frequentist-statistics.html"><i class="fa fa-check"></i><b>A.3</b> Material on <em>frequentist statistics</em>:</a></li>
<li class="chapter" data-level="A.4" data-path="material-on-r-tidyverse-etc-.html"><a href="material-on-r-tidyverse-etc-.html"><i class="fa fa-check"></i><b>A.4</b> Material on <em>R, tidyverse, etc.</em>:</a></li>
<li class="chapter" data-level="A.5" data-path="further-information-for-rstudio.html"><a href="further-information-for-rstudio.html"><i class="fa fa-check"></i><b>A.5</b> Further information for RStudio</a></li>
<li class="chapter" data-level="A.6" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html"><i class="fa fa-check"></i><b>A.6</b> Further information on WebPPL</a><ul>
<li class="chapter" data-level="A.6.1" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#primitives-and-sampling-functions"><i class="fa fa-check"></i><b>A.6.1</b> Primitives and sampling functions</a></li>
<li class="chapter" data-level="A.6.2" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#inference-with-infer"><i class="fa fa-check"></i><b>A.6.2</b> Inference with <code>Infer()</code></a></li>
<li class="chapter" data-level="A.6.3" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#visualization"><i class="fa fa-check"></i><b>A.6.3</b> Visualization</a></li>
<li class="chapter" data-level="A.6.4" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#installation"><i class="fa fa-check"></i><b>A.6.4</b> Installation</a></li>
<li class="chapter" data-level="A.6.5" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#usage"><i class="fa fa-check"></i><b>A.6.5</b> Usage</a></li>
<li class="chapter" data-level="A.6.6" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#keyboard-shortcuts-for-in-browser-use"><i class="fa fa-check"></i><b>A.6.6</b> Keyboard shortcuts (for in-browser use)</a></li>
<li class="chapter" data-level="A.6.7" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#further-resources"><i class="fa fa-check"></i><b>A.6.7</b> Further resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="app-91-distributions.html"><a href="app-91-distributions.html"><i class="fa fa-check"></i><b>B</b> Common probability distributions</a><ul>
<li class="chapter" data-level="B.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.1</b> Selected continuous distributions of random variables</a><ul>
<li class="chapter" data-level="B.1.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-normal"><i class="fa fa-check"></i><b>B.1.1</b> Normal distribution</a></li>
<li class="chapter" data-level="B.1.2" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-chi2"><i class="fa fa-check"></i><b>B.1.2</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="B.1.3" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#f-distribution"><i class="fa fa-check"></i><b>B.1.3</b> F-distribution</a></li>
<li class="chapter" data-level="B.1.4" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-students-t"><i class="fa fa-check"></i><b>B.1.4</b> Student’s <em>t</em>-distribution</a></li>
<li class="chapter" data-level="B.1.5" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-beta"><i class="fa fa-check"></i><b>B.1.5</b> Beta distribution</a></li>
<li class="chapter" data-level="B.1.6" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#uniform-distribution"><i class="fa fa-check"></i><b>B.1.6</b> Uniform distribution</a></li>
<li class="chapter" data-level="B.1.7" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-dirichlet"><i class="fa fa-check"></i><b>B.1.7</b> Dirichlet distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.2</b> Selected discrete distributions of random variables</a><ul>
<li class="chapter" data-level="B.2.1" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-binomial"><i class="fa fa-check"></i><b>B.2.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="B.2.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-multinomial"><i class="fa fa-check"></i><b>B.2.2</b> Multinomial distribution</a></li>
<li class="chapter" data-level="B.2.3" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-bernoulli"><i class="fa fa-check"></i><b>B.2.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="B.2.4" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-categorical"><i class="fa fa-check"></i><b>B.2.4</b> Categorical distribution</a></li>
<li class="chapter" data-level="B.2.5" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-beta-binomial"><i class="fa fa-check"></i><b>B.2.5</b> Beta-Binomial distribution</a></li>
<li class="chapter" data-level="B.2.6" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#poisson-distribution"><i class="fa fa-check"></i><b>B.2.6</b> Poisson distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="app-92-exponential-family.html"><a href="app-92-exponential-family.html"><i class="fa fa-check"></i><b>C</b> Exponential Family and Maximum Entropy</a><ul>
<li class="chapter" data-level="C.1" data-path="an-important-family-the-exponential-family.html"><a href="an-important-family-the-exponential-family.html"><i class="fa fa-check"></i><b>C.1</b> An important family: The Exponential Family</a></li>
<li class="chapter" data-level="C.2" data-path="the-maximum-entropy-principle.html"><a href="the-maximum-entropy-principle.html"><i class="fa fa-check"></i><b>C.2</b> The Maximum Entropy Principle</a><ul>
<li class="chapter" data-level="C.2.1" data-path="the-maximum-entropy-principle.html"><a href="the-maximum-entropy-principle.html#information-entropy"><i class="fa fa-check"></i><b>C.2.1</b> Information Entropy</a></li>
<li class="chapter" data-level="C.2.2" data-path="the-maximum-entropy-principle.html"><a href="the-maximum-entropy-principle.html#deriving-probability-distributions-using-the-maximum-entropy-principle"><i class="fa fa-check"></i><b>C.2.2</b> Deriving Probability Distributions using the Maximum Entropy Principle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="app-93-data-sets.html"><a href="app-93-data-sets.html"><i class="fa fa-check"></i><b>D</b> Data sets used in the book</a><ul>
<li class="chapter" data-level="D.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html"><i class="fa fa-check"></i><b>D.1</b> Mental Chronometry</a><ul>
<li class="chapter" data-level="D.1.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#nature-origin-and-rationale-of-the-data"><i class="fa fa-check"></i><b>D.1.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.1.2" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#loading-and-preprocessing-the-data"><i class="fa fa-check"></i><b>D.1.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.1.3" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#cleaning-the-data-1"><i class="fa fa-check"></i><b>D.1.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.1.4" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#exploration-summary-stats-plots"><i class="fa fa-check"></i><b>D.1.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.1.5" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#data-analysis"><i class="fa fa-check"></i><b>D.1.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html"><i class="fa fa-check"></i><b>D.2</b> Simon Task</a><ul>
<li class="chapter" data-level="D.2.1" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html#experiment"><i class="fa fa-check"></i><b>D.2.1</b> Experiment</a></li>
<li class="chapter" data-level="D.2.2" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html#hypotheses"><i class="fa fa-check"></i><b>D.2.2</b> Hypotheses</a></li>
<li class="chapter" data-level="D.2.3" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html#results"><i class="fa fa-check"></i><b>D.2.3</b> Results</a></li>
<li class="chapter" data-level="D.2.4" data-path="app-93-data-sets-simon-task.html"><a href="app-93-data-sets-simon-task.html#statistical-analysis"><i class="fa fa-check"></i><b>D.2.4</b> Statistical analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html"><i class="fa fa-check"></i><b>D.3</b> World Values Survey (wave 6 | 2010-2014)</a><ul>
<li class="chapter" data-level="D.3.1" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html#nature-origin-and-rationale-of-the-data-1"><i class="fa fa-check"></i><b>D.3.1</b> Nature, origin and rationale of the data</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html"><i class="fa fa-check"></i><b>D.4</b> King of France</a><ul>
<li class="chapter" data-level="D.4.1" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#app-93-data-sets-king-of-france-background"><i class="fa fa-check"></i><b>D.4.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.4.2" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#loading-and-preprocessing-the-data-1"><i class="fa fa-check"></i><b>D.4.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.4.3" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#cleaning-the-data-3"><i class="fa fa-check"></i><b>D.4.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.4.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#exploration-summary-stats-plots-1"><i class="fa fa-check"></i><b>D.4.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.4.5" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#data-analysis-1"><i class="fa fa-check"></i><b>D.4.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html"><i class="fa fa-check"></i><b>D.5</b> Bio-Logic Jazz-Metal (and where to consume it)</a><ul>
<li class="chapter" data-level="D.5.1" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#nature-origin-and-rationale-of-the-data-2"><i class="fa fa-check"></i><b>D.5.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.5.2" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#loading-and-preprocessing-the-data-2"><i class="fa fa-check"></i><b>D.5.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.5.3" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#exploration-counts-plots"><i class="fa fa-check"></i><b>D.5.3</b> Exploration: counts &amp; plots</a></li>
</ul></li>
<li class="chapter" data-level="D.6" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html"><i class="fa fa-check"></i><b>D.6</b> Avocado prices</a><ul>
<li class="chapter" data-level="D.6.1" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#nature-origin-and-rationale-of-the-data-3"><i class="fa fa-check"></i><b>D.6.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.6.2" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#loading-and-preprocessing-the-data-3"><i class="fa fa-check"></i><b>D.6.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.6.3" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#summary-statistics"><i class="fa fa-check"></i><b>D.6.3</b> Summary statistics</a></li>
<li class="chapter" data-level="D.6.4" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#plots"><i class="fa fa-check"></i><b>D.6.4</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="D.7" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html"><i class="fa fa-check"></i><b>D.7</b> Annual average world surface temperature</a><ul>
<li class="chapter" data-level="D.7.1" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#nature-origin-and-rationale-of-the-data-4"><i class="fa fa-check"></i><b>D.7.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.7.2" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#loading-and-preprocessing-the-data-4"><i class="fa fa-check"></i><b>D.7.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.7.3" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#hypothesis-modeling-approach"><i class="fa fa-check"></i><b>D.7.3</b> Hypothesis &amp; modeling approach</a></li>
<li class="chapter" data-level="D.7.4" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#plotting"><i class="fa fa-check"></i><b>D.7.4</b> Plotting</a></li>
<li class="chapter" data-level="D.7.5" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#analysis"><i class="fa fa-check"></i><b>D.7.5</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.8" data-path="app-93-data-sets-murder-data.html"><a href="app-93-data-sets-murder-data.html"><i class="fa fa-check"></i><b>D.8</b> Murder data</a><ul>
<li class="chapter" data-level="D.8.1" data-path="app-93-data-sets-murder-data.html"><a href="app-93-data-sets-murder-data.html#nature-origin-and-rationale-of-the-data-5"><i class="fa fa-check"></i><b>D.8.1</b> Nature, origin and rationale of the data</a></li>
</ul></li>
<li class="chapter" data-level="D.9" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html"><i class="fa fa-check"></i><b>D.9</b> Politeness data</a><ul>
<li class="chapter" data-level="D.9.1" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#nature-origin-and-rationale-of-the-data-6"><i class="fa fa-check"></i><b>D.9.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.9.2" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#hypotheses-2"><i class="fa fa-check"></i><b>D.9.2</b> Hypotheses</a></li>
<li class="chapter" data-level="D.9.3" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#summary-statistics-1"><i class="fa fa-check"></i><b>D.9.3</b> Summary statistics</a></li>
<li class="chapter" data-level="D.9.4" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#visualization-1"><i class="fa fa-check"></i><b>D.9.4</b> Visualization</a></li>
<li class="chapter" data-level="D.9.5" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#analysis-1"><i class="fa fa-check"></i><b>D.9.5</b> Analysis</a></li>
<li class="chapter" data-level="D.9.6" data-path="app-93-data-sets-politeness.html"><a href="app-93-data-sets-politeness.html#anova"><i class="fa fa-check"></i><b>D.9.6</b> ANOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="app-94-open-science.html"><a href="app-94-open-science.html"><i class="fa fa-check"></i><b>E</b> Open science practices</a><ul>
<li class="chapter" data-level="E.1" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html"><i class="fa fa-check"></i><b>E.1</b> Psychology’s replication crisis</a><ul>
<li class="chapter" data-level="E.1.1" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html#publication-bias-qrps-and-false-positives"><i class="fa fa-check"></i><b>E.1.1</b> Publication bias, QRP’s, and false-positives</a></li>
<li class="chapter" data-level="E.1.2" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html#low-statistical-power"><i class="fa fa-check"></i><b>E.1.2</b> Low statistical power</a></li>
<li class="chapter" data-level="E.1.3" data-path="app-94-replication-crisis.html"><a href="app-94-replication-crisis.html#lack-of-transparency"><i class="fa fa-check"></i><b>E.1.3</b> Lack of transparency</a></li>
</ul></li>
<li class="chapter" data-level="E.2" data-path="app-94-remedies.html"><a href="app-94-remedies.html"><i class="fa fa-check"></i><b>E.2</b> Possible remedies</a><ul>
<li class="chapter" data-level="E.2.1" data-path="app-94-remedies.html"><a href="app-94-remedies.html#improve-scientific-rigor"><i class="fa fa-check"></i><b>E.2.1</b> Improve scientific rigor</a></li>
<li class="chapter" data-level="E.2.2" data-path="app-94-remedies.html"><a href="app-94-remedies.html#realigning-incentive-structures"><i class="fa fa-check"></i><b>E.2.2</b> Realigning incentive structures</a></li>
<li class="chapter" data-level="E.2.3" data-path="app-94-remedies.html"><a href="app-94-remedies.html#promote-transparency"><i class="fa fa-check"></i><b>E.2.3</b> Promote transparency</a></li>
</ul></li>
<li class="chapter" data-level="E.3" data-path="app-94-recap.html"><a href="app-94-recap.html"><i class="fa fa-check"></i><b>E.3</b> Chapter summary</a></li>
<li class="chapter" data-level="E.4" data-path="app-94-resources.html"><a href="app-94-resources.html"><i class="fa fa-check"></i><b>E.4</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-03-05-hypothesis-testing-tests" class="section level2">
<h2><span class="header-section-number">16.3</span> Selected tests</h2>
<div id="ch-03-05-hypothesis-testing-Pearsons-Chi" class="section level3">
<h3><span class="header-section-number">16.3.1</span> Pearson’s <span class="math inline">\(\chi^2\)</span>-tests</h3>
<p>There are many tests that use the <a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-chi2"><span class="math inline">\(\chi^2\)</span>-distribution</a> as an (approximate) sampling distribution. But given relevance and historical prominence, the name “<span class="math inline">\(\chi^2\)</span>-test” is usually interpreted to refer to one of several flavor’s of what we could specifically call “Pearson’s <span class="math inline">\(\chi^2\)</span>-test”.</p>
<p>We will look at two flavors here. Pearson’s <span class="math inline">\(\chi^2\)</span>-test for <strong>goodness of fit</strong> tests whether an observed vector of counts is well explained by a given vector of predicted proportion. Pearson’s <span class="math inline">\(\chi^2\)</span>-test for <strong>independence</strong> tests whether a (two-dimensional) table of counts could plausibly have been generated by a process of independently selecting the column and the row category. We will explain how both of these tests work based on an application of the <a href="app-93-data-sets-BLJM.html#app-93-data-sets-BLJM">BLJM data</a>, which we load as usual:</p>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb621-1" data-line-number="1">data_BLJM_processed &lt;-<span class="st"> </span>aida<span class="op">::</span>data_BLJM</a></code></pre></div>
<p>The focus is on the counts of music-subject choices:</p>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb622-1" data-line-number="1">BLJM_associated_counts &lt;-<span class="st"> </span>data_BLJM_processed <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb622-2" data-line-number="2"><span class="st">  </span><span class="kw">select</span>(submission_id, condition, response) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb622-3" data-line-number="3"><span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> condition, <span class="dt">values_from =</span> response) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb622-4" data-line-number="4"><span class="st">  </span><span class="co"># drop the Beach-vs-Mountain condition</span></a>
<a class="sourceLine" id="cb622-5" data-line-number="5"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>BM) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb622-6" data-line-number="6"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">count</span>(JM,LB) </a>
<a class="sourceLine" id="cb622-7" data-line-number="7">BLJM_associated_counts</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   JM    LB          n
##   &lt;chr&gt; &lt;chr&gt;   &lt;int&gt;
## 1 Jazz  Biology    38
## 2 Jazz  Logic      26
## 3 Metal Biology    20
## 4 Metal Logic      18</code></pre>
<p>Remember that the lecturer’s bold conjecture was that a preference for Logic over Biology goes together with a preference for Metal over Jazz. The visualization suggests that there might be such a trend, but the (statistical) jury is still out as to whether this conjecture has empirical support.</p>
<div id="pearsons-chi2-test-for-goodness-of-fit" class="section level4">
<h4><span class="header-section-number">16.3.1.1</span> Pearson’s <span class="math inline">\(\chi^2\)</span>-test for goodness of fit</h4>
<p>“Goodness of fit” is a term used in model checking (a.k.a. model criticism, model validation, …). In such a context, tests for goodness-of-fit investigate whether a model’s predictions are compatible with the observed data. Pearson’s <span class="math inline">\(\chi^2\)</span>-test for goodness of fit does exactly this for categorical data.</p>
<p>Categorical data is data where each data observation falls into one of several unordered categories. If we have <span class="math inline">\(k\)</span> such categories, a <strong>prediction vector</strong> <span class="math inline">\(\vec{p} = \langle p_1, \dots, p_k \rangle\)</span> is a probability vector of length <span class="math inline">\(k\)</span> such that <span class="math inline">\(p_i\)</span> gives the probability with which a single data observation falls into the <span class="math inline">\(i\)</span>-th category. The likelihood of a single data observation is given by the <a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-categorical">Categorical distribution</a>, and the likelihood of <span class="math inline">\(N\)</span> data observations is given by the <a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-multinomial">Multinomial distribution</a>. These are generalizations of the Bernoulli and Binomial distributions, which expand the case of two unordered categories to more than two unordered categories.</p>
<p>The BLJM data supplies us with categorical data. Here is the vector of counts of how many participants selected a given music+subject pair:</p>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb624-1" data-line-number="1"><span class="co"># add category names</span></a>
<a class="sourceLine" id="cb624-2" data-line-number="2">BLJM_associated_counts &lt;-<span class="st"> </span>BLJM_associated_counts <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb624-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb624-4" data-line-number="4">    <span class="dt">category =</span> <span class="kw">str_c</span>(</a>
<a class="sourceLine" id="cb624-5" data-line-number="5">      BLJM_associated_counts <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(LB),</a>
<a class="sourceLine" id="cb624-6" data-line-number="6">      <span class="st">&quot;-&quot;</span>,</a>
<a class="sourceLine" id="cb624-7" data-line-number="7">      BLJM_associated_counts <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(JM)</a>
<a class="sourceLine" id="cb624-8" data-line-number="8">    )</a>
<a class="sourceLine" id="cb624-9" data-line-number="9">  )</a>
<a class="sourceLine" id="cb624-10" data-line-number="10">counts_BLJM_choice_pairs_vector &lt;-<span class="st"> </span>BLJM_associated_counts <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(n)</a>
<a class="sourceLine" id="cb624-11" data-line-number="11"><span class="kw">names</span>(counts_BLJM_choice_pairs_vector) &lt;-<span class="st"> </span>BLJM_associated_counts <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(category)</a>
<a class="sourceLine" id="cb624-12" data-line-number="12">counts_BLJM_choice_pairs_vector</a></code></pre></div>
<pre><code>##  Biology-Jazz    Logic-Jazz Biology-Metal   Logic-Metal 
##            38            26            20            18</code></pre>
<p>Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-BLJM-count-pairs-plot">16.7</a> shows a crude plot of these counts, together with a baseline prediction of equal proportion in each category.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-BLJM-count-pairs-plot"></span>
<img src="I2DA_files/figure-html/ch-03-04-BLJM-count-pairs-plot-1.png" alt="Observed counts of choice pairs of music+subject preference in the BLJM data." width="672" />
<p class="caption">
Figure 16.7: Observed counts of choice pairs of music+subject preference in the BLJM data.
</p>
</div>
<p>Pearson’s <span class="math inline">\(\chi^2\)</span>-test for goodness of fit allows us to test whether this data could plausibly have been generated by (a model whose predictions are given by) a prediction vector <span class="math inline">\(\vec{p} = \langle p_1, \dots, p_4 \rangle\)</span>, where <span class="math inline">\(p_1\)</span> would be the predicted probability of a choice pair “Biology-Jazz” occurring for a single participant, and so on. Frequently, this test is used to check whether an equal baseline distribution could have generated the data. We do that here, too. We form the null hypothesis that <span class="math inline">\(\vec{p} = \vec{p}_0\)</span> with <span class="math inline">\(p_{0i} = \frac{1}{4}\)</span> for all categories <span class="math inline">\(i\)</span>.</p>
<p>Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-chi2-model-goodness">16.8</a> shows a graphical representation of the model implicitly assumed in the background for a Pearson’s <span class="math inline">\(\chi^2\)</span>-test for goodness of fit. The model assumes that the observed vector of counts (like our <code>counts_BLJM_choice_pairs_vector</code> from above) follows a Multinomial distribution.<a href="#fn84" class="footnote-ref" id="fnref84"><sup>84</sup></a> Each vector of (hypothetical) data is associated with a test statistic, called <span class="math inline">\(\chi^2\)</span>, which sums over the standardized squared deviation of the observed counts from the predicted baseline in each cell. It can be shown that, if the number of observations <span class="math inline">\(N\)</span> is large enough, the sampling distribution of the <span class="math inline">\(\chi^2\)</span> test statistic is approximated well enough by the <a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-chi2"><span class="math inline">\(\chi^2\)</span>-distribution</a> with <span class="math inline">\(k-1\)</span> degrees of freedom (where <span class="math inline">\(k\)</span> is the number of categories).<a href="#fn85" class="footnote-ref" id="fnref85"><sup>85</sup></a> Notice that the approximation by a <span class="math inline">\(\chi^2\)</span>-distribution hinges on an approximation, which is only met when there are enough samples (just as we needed in the CLT). A rule-of-thumb is that at most 20% of all cells should have expected frequencies below 5 in order for the test to be applicable, i.e., <span class="math inline">\(np_i &lt; 5\)</span> for all <span class="math inline">\(i\)</span> in Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-chi2-model-goodness">16.8</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-chi2-model-goodness"></span>
<img src="visuals/chi2-model-goodness.png" alt="Graphical representation of Pearson's $\chi^2$-test for goodness of fit (testing a vector of predicted proportion)." width="90%" />
<p class="caption">
Figure 16.8: Graphical representation of Pearson’s <span class="math inline">\(\chi^2\)</span>-test for goodness of fit (testing a vector of predicted proportion).
</p>
</div>
<p>We can compute the <span class="math inline">\(\chi^2\)</span>-value associated with the observed data <span class="math inline">\(t(D_{obs})\)</span> as follows:</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb626-1" data-line-number="1"><span class="co"># observed counts</span></a>
<a class="sourceLine" id="cb626-2" data-line-number="2">n &lt;-<span class="st"> </span>counts_BLJM_choice_pairs_vector</a>
<a class="sourceLine" id="cb626-3" data-line-number="3"><span class="co"># proportion predicted </span></a>
<a class="sourceLine" id="cb626-4" data-line-number="4">p &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>,<span class="dv">4</span>)</a>
<a class="sourceLine" id="cb626-5" data-line-number="5"><span class="co"># expected number in each cell</span></a>
<a class="sourceLine" id="cb626-6" data-line-number="6">e &lt;-<span class="st"> </span><span class="kw">sum</span>(n)<span class="op">*</span>p</a>
<a class="sourceLine" id="cb626-7" data-line-number="7"><span class="co"># chi-squared for observed data</span></a>
<a class="sourceLine" id="cb626-8" data-line-number="8">chi2_observed &lt;-<span class="st"> </span><span class="kw">sum</span>((n<span class="op">-</span>e)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>e)</a>
<a class="sourceLine" id="cb626-9" data-line-number="9">chi2_observed</a></code></pre></div>
<pre><code>## [1] 9.529412</code></pre>
<p>We can then compare this value to the sampling distribution, which is a <span class="math inline">\(\chi^2\)</span>-distribution with <span class="math inline">\(k-1 = 3\)</span> degrees of freedom. We compute the <span class="math inline">\(p\)</span>-value associated with our data as the tail of the sampling distribution, as also shown in Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-chi2-plot">16.9</a>:<a href="#fn86" class="footnote-ref" id="fnref86"><sup>86</sup></a></p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb628-1" data-line-number="1">p_value_BLJM &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(chi2_observed, <span class="dt">df =</span> <span class="dv">3</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-chi2-plot"></span>
<img src="I2DA_files/figure-html/ch-03-04-chi2-plot-1.png" alt="Sampling distribution for a Pearson's $\chi^2$-test of goodness of fit ($\chi^2$-distribution with $k-1 = 3$ degrees of freedom), testing a flat baseline null hypothesis based on the BLJM data." width="90%" />
<p class="caption">
Figure 16.9: Sampling distribution for a Pearson’s <span class="math inline">\(\chi^2\)</span>-test of goodness of fit (<span class="math inline">\(\chi^2\)</span>-distribution with <span class="math inline">\(k-1 = 3\)</span> degrees of freedom), testing a flat baseline null hypothesis based on the BLJM data.
</p>
</div>
<p>Of course, these calculations can also be performed by using a built-in R function, namely <code>chisq.test</code>:</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb629-1" data-line-number="1">counts_BLJM_choice_pairs_vector &lt;-<span class="st"> </span>BLJM_associated_counts <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(n)</a>
<a class="sourceLine" id="cb629-2" data-line-number="2"><span class="kw">chisq.test</span>(counts_BLJM_choice_pairs_vector)</a></code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  counts_BLJM_choice_pairs_vector
## X-squared = 9.5294, df = 3, p-value = 0.02302</code></pre>
<p>The common interpretation of our calculations would be to say that the test yielded a significant result, at least at the significance level of <span class="math inline">\(\alpha = 0.5\)</span>. In a research paper, we might report these results roughly as follows:</p>
<blockquote>
<p>Observed counts deviated significantly from what is expected if each category (here: pair of music+subject choice) was equally likely (<span class="math inline">\(\chi^2\)</span>-test, with <span class="math inline">\(\chi^2 \approx 9.53\)</span>, <span class="math inline">\(df = 3\)</span> and <span class="math inline">\(p \approx 0.023\)</span>).</p>
</blockquote>
<p>Notice that this test is an “omnibus test of difference”. We can conclude from a significant test result that the whole vector of observations is unlikely to have been generated by chance. Still, we cannot conclude from this result (without doing anything else) why, where or how the observations deviated from the assumed prediction vector. Looking at the plot of the data in Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-BLJM-count-pairs-plot">16.7</a> above, it seems intuitive to think that Metal is disproportionally disfavored and that the combination of Biology and Jazz looks particularly outliery when compared to the baseline expectation.</p>
</div>
<div id="pearsons-chi2-test-of-independence" class="section level4">
<h4><span class="header-section-number">16.3.1.2</span> Pearson’s <span class="math inline">\(\chi^2\)</span>-test of independence</h4>
<p>The previous test of goodness of fit does not allow us to address the lecturer’s conjecture that a preference of Metal over Jazz goes with a preference of Logic over Biology. A slightly different kind of <span class="math inline">\(\chi^2\)</span>-test is better suited for this. In Pearson’s <span class="math inline">\(\chi^2\)</span>-test of independence, we look at a two-dimensional table of correlated data observations, like this one:</p>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb631-1" data-line-number="1">BLJM_table &lt;-<span class="st"> </span>BLJM_associated_counts <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb631-2" data-line-number="2"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>category) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb631-3" data-line-number="3"><span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> LB, <span class="dt">values_from =</span> n)</a>
<a class="sourceLine" id="cb631-4" data-line-number="4">BLJM_table</a></code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   JM    Biology Logic
##   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;
## 1 Jazz       38    26
## 2 Metal      20    18</code></pre>
<p>For easier computation and compatibility with the function <code>chisq.test</code>, we handle the same data but stored as a matrix:</p>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb633-1" data-line-number="1">counts_BLJM_choice_pairs_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(</a>
<a class="sourceLine" id="cb633-2" data-line-number="2">  counts_BLJM_choice_pairs_vector, </a>
<a class="sourceLine" id="cb633-3" data-line-number="3">  <span class="dt">nrow =</span> <span class="dv">2</span>, </a>
<a class="sourceLine" id="cb633-4" data-line-number="4">  <span class="dt">byrow =</span> T</a>
<a class="sourceLine" id="cb633-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb633-6" data-line-number="6"><span class="kw">rownames</span>(counts_BLJM_choice_pairs_matrix) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Jazz&quot;</span>, <span class="st">&quot;Metal&quot;</span>)</a>
<a class="sourceLine" id="cb633-7" data-line-number="7"><span class="kw">colnames</span>(counts_BLJM_choice_pairs_matrix) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Biology&quot;</span>, <span class="st">&quot;Logic&quot;</span>)</a>
<a class="sourceLine" id="cb633-8" data-line-number="8">counts_BLJM_choice_pairs_matrix</a></code></pre></div>
<pre><code>##       Biology Logic
## Jazz       38    26
## Metal      20    18</code></pre>
<p>Pearson’s <span class="math inline">\(\chi^2\)</span>-test of independence addresses the question of whether two-dimensional tabular count data like the above could plausibly have been generated by a prediction vector <span class="math inline">\(\vec{p}\)</span>, which results from the assumption that the realizations of row- and column-choices are <a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence">stochastically independent</a>. If row- and column-choices are independent, the probability of seeing an outcome result in cell <span class="math inline">\(ij\)</span> is the probability of realizing row <span class="math inline">\(i\)</span> times the probability of realizing column <span class="math inline">\(j\)</span>. So, under an independence assumption, we expect a matrix and a resulting vector of choice proportions like this:</p>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb635-1" data-line-number="1"><span class="co"># number of observations in total</span></a>
<a class="sourceLine" id="cb635-2" data-line-number="2">N &lt;-<span class="st"> </span><span class="kw">sum</span>(counts_BLJM_choice_pairs_matrix)</a>
<a class="sourceLine" id="cb635-3" data-line-number="3"><span class="co"># marginal proportions observed in the data </span></a>
<a class="sourceLine" id="cb635-4" data-line-number="4"><span class="co"># the following is the vector r in the model graph</span></a>
<a class="sourceLine" id="cb635-5" data-line-number="5">row_prob &lt;-<span class="st"> </span>counts_BLJM_choice_pairs_matrix <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rowSums</span>() <span class="op">/</span><span class="st"> </span>N</a>
<a class="sourceLine" id="cb635-6" data-line-number="6"><span class="co"># the following is the vector c in the model graph</span></a>
<a class="sourceLine" id="cb635-7" data-line-number="7">col_prob &lt;-<span class="st"> </span>counts_BLJM_choice_pairs_matrix <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">colSums</span>() <span class="op">/</span><span class="st"> </span>N</a>
<a class="sourceLine" id="cb635-8" data-line-number="8"><span class="co"># table of expected observations under independence assumption</span></a>
<a class="sourceLine" id="cb635-9" data-line-number="9"><span class="co"># NB: %o% is the outer product of vectors</span></a>
<a class="sourceLine" id="cb635-10" data-line-number="10">BLJM_expectation_matrix &lt;-<span class="st"> </span>(row_prob <span class="op">%o%</span><span class="st"> </span>col_prob) <span class="op">*</span><span class="st"> </span>N </a>
<a class="sourceLine" id="cb635-11" data-line-number="11">BLJM_expectation_matrix</a></code></pre></div>
<pre><code>##        Biology    Logic
## Jazz  36.39216 27.60784
## Metal 21.60784 16.39216</code></pre>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb637-1" data-line-number="1"><span class="co"># the following is the vector p in the model graph</span></a>
<a class="sourceLine" id="cb637-2" data-line-number="2">BLJM_expectation_vector &lt;-<span class="st"> </span><span class="kw">as.vector</span>(BLJM_expectation_matrix)</a>
<a class="sourceLine" id="cb637-3" data-line-number="3">BLJM_expectation_vector</a></code></pre></div>
<pre><code>## [1] 36.39216 21.60784 27.60784 16.39216</code></pre>
<p>Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-chi2-model-independence">16.10</a> shows a graphical representation of the <span class="math inline">\(\chi^2\)</span>-test of independence. The main difference to the previous test of goodness of fit is that we do no longer just fix any-old prediction vector <span class="math inline">\(\vec{p}\)</span>, but consider <span class="math inline">\(\vec{p}\)</span> the deterministic results of independence <em>and</em> the best estimates (based on the data at hand) of the row- and column probabilities.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-chi2-model-independence"></span>
<img src="visuals/chi2-model-independence.png" alt="Graphical representation of Pearson's $\chi^2$-test for independence." width="90%" />
<p class="caption">
Figure 16.10: Graphical representation of Pearson’s <span class="math inline">\(\chi^2\)</span>-test for independence.
</p>
</div>
<p>We can compute the observed <span class="math inline">\(\chi^2\)</span>-test statistic and the <span class="math inline">\(p\)</span>-value as follows:</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb639-1" data-line-number="1">chi2_observed &lt;-<span class="st"> </span><span class="kw">sum</span>(</a>
<a class="sourceLine" id="cb639-2" data-line-number="2">  (counts_BLJM_choice_pairs_matrix <span class="op">-</span><span class="st"> </span>BLJM_expectation_matrix)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span></a>
<a class="sourceLine" id="cb639-3" data-line-number="3"><span class="st">    </span>BLJM_expectation_matrix</a>
<a class="sourceLine" id="cb639-4" data-line-number="4">  )</a>
<a class="sourceLine" id="cb639-5" data-line-number="5">p_value_BLJM &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="dt">q =</span> chi2_observed, <span class="dt">df =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb639-6" data-line-number="6"><span class="kw">round</span>(p_value_BLJM, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] 0.50615</code></pre>
<p>Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-chi2-plot-independence">16.11</a> shows the sampling distribution, the value of the test statistic for the observed data and the <span class="math inline">\(p\)</span>-value.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-chi2-plot-independence"></span>
<img src="I2DA_files/figure-html/ch-03-04-chi2-plot-independence-1.png" alt="Sampling distribution for a Pearson's $\chi^2$ test of independence ($\chi^2$-distribution with $1$ degree of freedom), testing a flat baseline null hypothesis based on the BLJM data." width="90%" />
<p class="caption">
Figure 16.11: Sampling distribution for a Pearson’s <span class="math inline">\(\chi^2\)</span> test of independence (<span class="math inline">\(\chi^2\)</span>-distribution with <span class="math inline">\(1\)</span> degree of freedom), testing a flat baseline null hypothesis based on the BLJM data.
</p>
</div>
<p>We can also use the built-in function <code>chisq.test</code> in R to obtain this result more efficiently:</p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb641-1" data-line-number="1"><span class="kw">chisq.test</span>(</a>
<a class="sourceLine" id="cb641-2" data-line-number="2">  <span class="co"># supply data as a matrix, not as a vector, for a test of independence</span></a>
<a class="sourceLine" id="cb641-3" data-line-number="3">  counts_BLJM_choice_pairs_matrix, </a>
<a class="sourceLine" id="cb641-4" data-line-number="4">  <span class="co"># do not use the default correction (because we didn&#39;t introduce it)</span></a>
<a class="sourceLine" id="cb641-5" data-line-number="5">  <span class="dt">correct =</span> <span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb641-6" data-line-number="6">)</a></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  counts_BLJM_choice_pairs_matrix
## X-squared = 0.44202, df = 1, p-value = 0.5061</code></pre>
<p>With a <span class="math inline">\(p\)</span>-value of about 0.5061, we should conclude that there is no indication of strong evidence <em>against</em> the assumption of independence. Consequently, there is no evidence <em>in favor</em> of the lecturer’s conjecture of dependence of musical and academic preferences. In a research paper, we might report this result as follows:</p>
<blockquote>
<p>A <span class="math inline">\(\chi^2\)</span>-test of independence did not yield a significant test result (<span class="math inline">\(\chi^2\)</span>-test, with <span class="math inline">\(\chi^2 \approx 0.44\)</span>, <span class="math inline">\(df = 1\)</span> and <span class="math inline">\(p \approx 0.5\)</span>). Therefore, we cannot claim to have found any evidence for the research hypothesis of dependence.</p>
</blockquote>
<!-- exercise 2 -->
<!-- Taken from the prep exam (IDA-prep-exam-01.pdf) -->
<div class = "exercises">
<p><strong>Exercise 10.2: <span class="math inline">\(\chi^2\)</span>-test of independence</strong></p>
<p>Let us assume that there are two unordered categorical variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Categorical variable <span class="math inline">\(A\)</span> has two levels <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span>. Categorical variable <span class="math inline">\(B\)</span> has three levels <span class="math inline">\(b_1\)</span>, <span class="math inline">\(b_2\)</span> and <span class="math inline">\(b_3\)</span>. Let us further assume that the (marginal) probabilities of a choice from categories <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> is as follows:</p>
<p><span class="math display">\[
P(A=a_i)=\begin{cases}
          0.3 &amp;\textbf{if \(i=1\)} \\
          0.7 &amp;\textbf{if \(i=2\)}
          \end{cases}
\quad P(B=b_i)=\begin{cases}
                0.2 &amp;\textbf{if \(i=1\)}\\
                0.3 &amp;\textbf{if \(i=2\)}\\
                0.5 &amp;\textbf{if \(i=3\)}
               \end{cases}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>If observations of pairs of instances from categories <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are stochastically independent, what would the expected joint probability of each pair of potential observations be?</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">

<div align="center">

<table style='width:70%'>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(b_1\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(b_2\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(b_3\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(a_1\)</span>
</td>
<td style="text-align:center;">
.3 <span class="math inline">\(\times\)</span> .2 = .06
</td>
<td style="text-align:center;">
.3 <span class="math inline">\(\times\)</span> .3 = .09
</td>
<td style="text-align:center;">
.3 <span class="math inline">\(\times\)</span> .5 = .15
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(a_2\)</span>
</td>
<td style="text-align:center;">
.7 <span class="math inline">\(\times\)</span> .2 = .14
</td>
<td style="text-align:center;">
.7 <span class="math inline">\(\times\)</span> .3 = .21
</td>
<td style="text-align:center;">
.7 <span class="math inline">\(\times\)</span> .5 = .35
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Imagine you observe the following table of counts for each pair of instances of categories <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:</li>
</ol>
<div align="center">

<table style='width:70%'>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(b_1\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(b_2\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(b_3\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(a_1\)</span>
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(a_2\)</span>
</td>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
47
</td>
</tr>
</tbody>
</table>
</div>
<p>   Which of the <span class="math inline">\(p\)</span>-values given below would you expect to see when feeding this table into a
   Pearson <span class="math inline">\(\chi^2\)</span>-test of independence? (only one correct answer)</p>
<ol type="i" start="1" style="margin-left: 2em;">
<li>
<span class="math inline">\(p \approx 1\)</span>
</li>
<li>
<span class="math inline">\(p \approx 0.5\)</span>
</li>
<li>
<span class="math inline">\(p \approx 0\)</span>
</li>
<li>
I expect no result because the test is not suitable for this kind of data.
</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>The correct answer is <span class="math inline">\(p \approx 0\)</span>.</p>
</div>
</div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Explain the answer you gave in the previous part in at most three concise sentences.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>As the marginal proportions of observed counts for the table in b. equal the marginal probabilities given above, the joint probability table in a. actually gives the predicted probabilities under the assumption of independence. Comparing prediction against observed proportion (obtained by dividing the table in b. by the total count of 100), we see severe divergences, especially in the middle column.</p>
</div>
</div>
</div>
</div>
</div>
<div id="ch-03-05-hypothesis-testing-z-test" class="section level3">
<h3><span class="header-section-number">16.3.2</span> <em>z</em>-test</h3>
<p>The Central Limit Theorem tells us that, given enough data, we can treat means of repeated samples from any arbitrary probability distribution as approximately normally distributed. Notice in addition that if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are random variables following a normal distribution, then so is <span class="math inline">\(Z = X - Y\)</span> (see also the <a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-normal">chapter on the normal distribution</a>). It now becomes clear how research questions about means and differences between means (e.g., in the Mental Chronometry experiment) can be addressed, at least approximately: We conduct tests that hinge on a sampling distribution which is a normal distribution (usually a standard normal distribution).</p>
<p>The <span class="math inline">\(z\)</span>-test is perhaps the simplest of a family of tests that rely on normality of the sampling distribution. Unfortunately, what makes it so simple is also what makes it inapplicable in a wide range of cases. The <span class="math inline">\(z\)</span>-test assumes that a quantity that is normally distributed has an unknown mean (to be inferred by testing), but it also assumes that the <em>variance is known</em>. Since we do not know the variance in most cases of practical relevance, the <span class="math inline">\(z\)</span>-test needs to be replaced by a more adequate test, usually a test from the <span class="math inline">\(t\)</span>-test family, to be discussed below.</p>
<p>We start with the <span class="math inline">\(z\)</span>-test nonetheless because of the added benefit to our understanding. Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-z-test-model">16.12</a> shows the model that implicitly underlies a <span class="math inline">\(z\)</span>-test. It checks whether the data <span class="math inline">\(\vec{x}\)</span>, which are assumed to be normally distributed with known <span class="math inline">\(\sigma\)</span>, could have been generated by a hypothesized mean <span class="math inline">\(\mu = \mu_0\)</span>. The sampling distribution of the derived test statistic <span class="math inline">\(z\)</span> is a standard normal distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-z-test-model"></span>
<img src="visuals/z-test-model.png" alt="Graphical representation of a $z$-test." width="90%" />
<p class="caption">
Figure 16.12: Graphical representation of a <span class="math inline">\(z\)</span>-test.
</p>
</div>
<p>We know that IQ test results are normally distributed around a mean of 100 with a standard deviation of 15. This holds when the sample is representative of the whole population. But suppose we have reason to believe that the sample is from CogSci students. The standard deviation in a sample from CogSci students might still plausibly be fixed to 15, but we’d like to test the assumption that <em>this</em> sample was generated by a mean <span class="math inline">\(\mu = 100\)</span>, our null hypothesis.</p>
<p>For illustration, suppose we observed the following data set of IQ test results:</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb643-1" data-line-number="1"><span class="co"># fictitious IQ data</span></a>
<a class="sourceLine" id="cb643-2" data-line-number="2">IQ_data &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">87</span>, <span class="dv">91</span>, <span class="dv">93</span>, <span class="dv">97</span>, <span class="dv">100</span>, <span class="dv">101</span>, <span class="dv">103</span>, <span class="dv">104</span>, </a>
<a class="sourceLine" id="cb643-3" data-line-number="3">             <span class="dv">104</span>, <span class="dv">105</span>, <span class="dv">105</span>, <span class="dv">106</span>, <span class="dv">108</span>, <span class="dv">110</span>, <span class="dv">111</span>, </a>
<a class="sourceLine" id="cb643-4" data-line-number="4">             <span class="dv">112</span>, <span class="dv">114</span>, <span class="dv">115</span>, <span class="dv">119</span>, <span class="dv">121</span>)</a>
<a class="sourceLine" id="cb643-5" data-line-number="5"><span class="kw">mean</span>(IQ_data)</a></code></pre></div>
<pre><code>## [1] 105.3</code></pre>
<p>The mean of this data set is 105.3. Suspicious!</p>
<p>Following the model in Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-z-test-model">16.12</a>, we calculate the value of the test statistic for the observed data.</p>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb645-1" data-line-number="1"><span class="co"># number of observations</span></a>
<a class="sourceLine" id="cb645-2" data-line-number="2">N &lt;-<span class="st"> </span><span class="kw">length</span>(IQ_data)</a>
<a class="sourceLine" id="cb645-3" data-line-number="3"><span class="co"># null hypothesis to test</span></a>
<a class="sourceLine" id="cb645-4" data-line-number="4">mu_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb645-5" data-line-number="5"><span class="co"># standard deviation (known/assumed as true)</span></a>
<a class="sourceLine" id="cb645-6" data-line-number="6">sd &lt;-<span class="st"> </span><span class="dv">15</span></a>
<a class="sourceLine" id="cb645-7" data-line-number="7">z_observed &lt;-<span class="st"> </span>(<span class="kw">mean</span>(IQ_data) <span class="op">-</span><span class="st"> </span>mu_<span class="dv">0</span>) <span class="op">/</span><span class="st"> </span>(sd <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(N))</a>
<a class="sourceLine" id="cb645-8" data-line-number="8">z_observed <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">4</span>)</a></code></pre></div>
<pre><code>## [1] 1.5802</code></pre>
<p>We focus on a one-sided <span class="math inline">\(p\)</span>-value because our “research” hypothesis is that CogSci students have, on average, a higher IQ. Since we observed a mean of 105.3 in the data, which is higher than the critical value of 100, we test the null hypothesis <span class="math inline">\(\mu = 100\)</span> against an alternative hypothesis that assumes that the data was generated by a mean <em>bigger</em> than 100 (which is exactly our research hypothesis).</p>
<p>As before, we can then compute the <span class="math inline">\(p\)</span>-value by checking the area under the sampling distribution, here a standard normal, in the appropriate way. Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-z-test">16.13</a> shows this result graphically.</p>
<div class="sourceCode" id="cb647"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb647-1" data-line-number="1">p_value_IQ_data_ztest &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(z_observed)</a>
<a class="sourceLine" id="cb647-2" data-line-number="2">p_value_IQ_data_ztest <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.057036</code></pre>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-z-test"></span>
<img src="I2DA_files/figure-html/ch-03-04-z-test-1.png" alt="Sampling distribution for a $z$-test, testing the null hypothesis based on the assumption that the IQ-data was generated by $\mu = 100$ (with assumed/known $\sigma$)." width="90%" />
<p class="caption">
Figure 16.13: Sampling distribution for a <span class="math inline">\(z\)</span>-test, testing the null hypothesis based on the assumption that the IQ-data was generated by <span class="math inline">\(\mu = 100\)</span> (with assumed/known <span class="math inline">\(\sigma\)</span>).
</p>
</div>
<p>We can also use a ready-made function for the <span class="math inline">\(z\)</span>-test. However, as the <span class="math inline">\(z\)</span>-test is so uncommon, it is not built into core R. We need to rely on the <code>BSDA</code> package to find the function <code>z.test</code>.</p>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb649-1" data-line-number="1">BSDA<span class="op">::</span><span class="kw">z.test</span>(<span class="dt">x =</span> IQ_data, <span class="dt">mu =</span> <span class="dv">100</span>, <span class="dt">sigma.x =</span> <span class="dv">15</span>, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<pre><code>## 
##  One-sample z-Test
## 
## data:  IQ_data
## z = 1.5802, p-value = 0.05704
## alternative hypothesis: true mean is greater than 100
## 95 percent confidence interval:
##  99.78299       NA
## sample estimates:
## mean of x 
##     105.3</code></pre>
<p>The conclusion to be drawn from this test could be formulated in a research report as follows:</p>
<blockquote>
<p>We tested the null hypothesis of a mean equal to 100, assuming a known standard deviation of 15, in a one-sided <span class="math inline">\(z\)</span>-test against the alternative hypothesis that the data was generated by a mean greater than 100 (our research hypothesis). The test was not significant (<span class="math inline">\(N = 20\)</span>, <span class="math inline">\(z \approx 1.5802\)</span>, <span class="math inline">\(p \approx 0.05704\)</span>), giving us no indication of strong evidence against the assumption that the mean is at most 100.</p>
</blockquote>
</div>
<div id="ch-03-05-hypothesis-testing-t-test" class="section level3">
<h3><span class="header-section-number">16.3.3</span> <em>t</em>-tests</h3>
<p>In most practical applications where a <span class="math inline">\(z\)</span>-test might be useful, the standard deviation is not known. If unknown, it should also not lightly be fixed by clever guess-work. This is where the family of <span class="math inline">\(t\)</span>-tests comes in. We will look at two examples of these: the one-sample <span class="math inline">\(t\)</span>-test, which compares one set of samples to a fixed mean, and the two-sample <span class="math inline">\(t\)</span>-test, which compares the means of two sets of samples.</p>
<div id="one-sample-t-test" class="section level4">
<h4><span class="header-section-number">16.3.3.1</span> One-sample <span class="math inline">\(t\)</span>-test</h4>
<p>The simplest example of this family, namely a <span class="math inline">\(t\)</span>-test for one metric vector <span class="math inline">\(\vec{x}\)</span> of normally distributed observations, tests the null hypothesis that <span class="math inline">\(\vec{x}\)</span> was generated by some <span class="math inline">\(\mu = \mu_0\)</span> (just like the <span class="math inline">\(z\)</span>-test). However, unlike the <span class="math inline">\(z\)</span>-test, a one-sample <span class="math inline">\(t\)</span>-test does not assume that the standard deviation is known. It rather uses the observed data to obtain an estimate for this parameter. More concretely, a one-sample <span class="math inline">\(t\)</span>-test for <span class="math inline">\(\vec{x}\)</span> estimates the standard deviation in the usual way (see Chapter <a href="Chap-02-03-summary-statistics.html#Chap-02-03-summary-statistics">5</a>):</p>
<p><span class="math display">\[\hat{\sigma}_x = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_i - \mu_{\vec{x}})^2}\]</span></p>
<p>Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-t-test-model-one-population">16.14</a> shows a graphical representation of a one-sample <span class="math inline">\(t\)</span>-test model. The light shading of the node for the standard deviation indicates that this parameter is estimated from the observed data. Importantly, the distribution of the test statistic <span class="math inline">\(t\)</span> is no longer well approximated by a normal distribution when the sample size is low. It is better captured by a <a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-students-t">Student’s <span class="math inline">\(t\)</span> distribution</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-t-test-model-one-population"></span>
<img src="visuals/t-test-model-one-population.png" alt="Graphical representation of the model underlying a frequentist one-sample $t$-test. Notice that the lightly shaded node for the standard deviation represents that the value for this parameter is estimated from the data." width="60%" />
<p class="caption">
Figure 16.14: Graphical representation of the model underlying a frequentist one-sample <span class="math inline">\(t\)</span>-test. Notice that the lightly shaded node for the standard deviation represents that the value for this parameter is estimated from the data.
</p>
</div>
<p>Let’s revisit our IQ-data set from above to calculate a <span class="math inline">\(t\)</span>-test. Using a <span class="math inline">\(t\)</span>-test implies that we are now assuming that the standard deviation is actually unknown. We can calculate the value of the test statistic for the observed data and use this to compute a <span class="math inline">\(p\)</span>-value, much like in the case of the <span class="math inline">\(z\)</span>-test before.</p>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb651-1" data-line-number="1">N &lt;-<span class="st"> </span><span class="kw">length</span>(IQ_data)</a>
<a class="sourceLine" id="cb651-2" data-line-number="2"><span class="co"># fix the null hypothesis</span></a>
<a class="sourceLine" id="cb651-3" data-line-number="3">mean_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb651-4" data-line-number="4"><span class="co"># unlike in a z-test, we use the sample to estimate the SD</span></a>
<a class="sourceLine" id="cb651-5" data-line-number="5">sigma_hat &lt;-<span class="st"> </span><span class="kw">sd</span>(IQ_data) </a>
<a class="sourceLine" id="cb651-6" data-line-number="6">t_observed &lt;-<span class="st"> </span>(<span class="kw">mean</span>(IQ_data) <span class="op">-</span><span class="st"> </span>mean_<span class="dv">0</span>) <span class="op">/</span><span class="st"> </span>sigma_hat <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(N)</a>
<a class="sourceLine" id="cb651-7" data-line-number="7">t_observed <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">4</span>)</a></code></pre></div>
<pre><code>## [1] 2.6446</code></pre>
<p>We calculate the relevant one-sided <span class="math inline">\(p\)</span>-value using the cumulative distribution function <code>pt</code> of the <span class="math inline">\(t\)</span>-distribution.</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb653-1" data-line-number="1">p_value_t_test_IQ &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(t_observed, <span class="dt">df =</span> N<span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb653-2" data-line-number="2">p_value_t_test_IQ <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.007992</code></pre>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-t-test-one-sample"></span>
<img src="I2DA_files/figure-html/ch-03-04-t-test-one-sample-1.png" alt="Sampling distribution for a $t$-test, testing the null hypothesis that the IQ-data was generated by $\mu = 100$ (with unknown $\sigma$)." width="90%" />
<p class="caption">
Figure 16.15: Sampling distribution for a <span class="math inline">\(t\)</span>-test, testing the null hypothesis that the IQ-data was generated by <span class="math inline">\(\mu = 100\)</span> (with unknown <span class="math inline">\(\sigma\)</span>).
</p>
</div>
<p>Compare these calculations against the built-in function <code>t.test</code>:</p>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb655-1" data-line-number="1"><span class="kw">t.test</span>(<span class="dt">x =</span> IQ_data, <span class="dt">mu =</span> <span class="dv">100</span>, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  IQ_data
## t = 2.6446, df = 19, p-value = 0.007992
## alternative hypothesis: true mean is greater than 100
## 95 percent confidence interval:
##  101.8347      Inf
## sample estimates:
## mean of x 
##     105.3</code></pre>
<p>These results could be stated in a research report much like so:</p>
<blockquote>
<p>We tested the null hypothesis of a mean equal to 100, assuming an unknown standard deviation, using a one-sided, one-sample <span class="math inline">\(t\)</span>-test against the alternative hypothesis that the data was generated by a mean greater than 100 (our research hypothesis). The significant test result (<span class="math inline">\(N = 20\)</span>, <span class="math inline">\(t \approx 2.6446\)</span>, <span class="math inline">\(p \approx 0.007992\)</span>) suggests that the data provides strong evidence against the assumption that the mean is not bigger than 100.</p>
</blockquote>
<p>Notice that the conclusions we draw from the previous <span class="math inline">\(z\)</span>-test and this one-sample <span class="math inline">\(t\)</span>-test are quite different. Why is this so? Well, it is because we (cheekily) chose a data set <code>IQ_data</code> that was actually <em>not</em> generated by a normal distribution with a standard deviation of 15, contrary to what we said about IQ-scores normally having this standard deviation. The assumption about <span class="math inline">\(\sigma\)</span> fed into the <span class="math inline">\(z\)</span>-test was (deliberately!) wrong. The result of the <span class="math inline">\(t\)</span>-test, at least for this example, is better. The data in <code>IQ_data</code> are actually samples from <span class="math inline">\(\text{Normal}(105,10)\)</span>. This demonstrates why the one-sample <span class="math inline">\(t\)</span>-test is usually preferred over a <span class="math inline">\(z\)</span>-test: unshakable, true knowledge of <span class="math inline">\(\sigma\)</span> is very rare.</p>
</div>
<div id="two-sample-t-test-for-unpaired-data-with-equal-variance-and-unequal-sample-sizes" class="section level4">
<h4><span class="header-section-number">16.3.3.2</span> Two-sample <span class="math inline">\(t\)</span>-test (for unpaired data with equal variance and unequal sample sizes)</h4>
<p>The “mother of all experimental designs” compares two groups of measurements. We give a drug to one group of patients, a placebo to another. We take a metric measure (say, blood sugar level) and ask whether there is a difference between these two groups. Section <a href="#Chap-03-03-models-examples"><strong>??</strong></a> introduced the <span class="math inline">\(T\)</span>-Test Model for a Bayesian approach. Here, we look at a corresponding model for a frequentist approach, a so-called two-sample <span class="math inline">\(t\)</span>-test. There are different kinds of such two-sample <span class="math inline">\(t\)</span>-tests. The differences lie, e.g., in whether we assume that both groups have equal variance, in whether the sample sizes are the same in both groups, or in whether observations are paired (e.g., as in a within-subjects design, where we get two measurements from each participant, one from each condition/group). Here, we focus on unpaired data (as from a between-subjects design), assume equal variance but (possibly) unequal sample sizes. The case we look at is the <a href="app-93-data-sets-avocado.html#app-93-data-sets-avocado">avocado data</a>, where we want to specifically investigate whether the weekly average price of organically grown avocados is higher than that of conventionally grown avocados.<a href="#fn87" class="footnote-ref" id="fnref87"><sup>87</sup></a></p>
<p>We here consider the preprocessed avocado data set (see Appendix Chapter <a href="app-93-data-sets-avocado.html#app-93-data-sets-avocado">D.6</a> for details on how this preprocessing was performed).</p>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb657-1" data-line-number="1">avocado_data &lt;-<span class="st"> </span>aida<span class="op">::</span>data_avocado</a></code></pre></div>
<p>Remember that the distribution of prices looks as follows:</p>
<p><img src="I2DA_files/figure-html/unnamed-chunk-451-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>A graphical representation of the two-sample <span class="math inline">\(t\)</span>-test (for unpaired data with equal variance and unequal sample sizes), which we will apply to this case, is shown in Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-t-test-model-two-populations">16.16</a>. The model assumes that we have two vectors of metric measurements <span class="math inline">\(\vec{x}_A\)</span> and <span class="math inline">\(\vec{x}_B\)</span>, with length <span class="math inline">\(n_A\)</span> and <span class="math inline">\(n_B\)</span>, respectively. These are the price measures for conventionally grown and for organically grown avocados. The model assumes that measures in both <span class="math inline">\(\vec{x}_A\)</span> and <span class="math inline">\(\vec{x}_B\)</span> are i.i.d. samples from a normal distribution. The mean of one group (group <span class="math inline">\(B\)</span> in the graph) is assumed to be some unknown <span class="math inline">\(\mu\)</span>. Interestingly, this parameter will cancel out eventually: the approximation of the sampling distribution turns out to be independent of this parameter.<a href="#fn88" class="footnote-ref" id="fnref88"><sup>88</sup></a> The mean of the other group (group <span class="math inline">\(A\)</span> in the graph) is computed as <span class="math inline">\(\mu + \delta\)</span>, so with some additive parameter <span class="math inline">\(\delta\)</span> indicating the difference between means of these groups. This <span class="math inline">\(\delta\)</span> is the main parameter of interest for inferences regarding hypotheses concerning differences between groups. Finally, the model assumes that both groups have the same standard deviation, an estimate of which is derived from the data (in a rather convoluted looking formula that is not important for our introductory concerns). As indicated in Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-t-test-model-two-populations">16.16</a>, the sampling distribution for this model is an instance of Student’s <span class="math inline">\(t\)</span>-distribution with mean 0, standard deviation 1 and degrees of freedom <span class="math inline">\(\nu\)</span> given as <span class="math inline">\(n_A + n_B - 2\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-t-test-model-two-populations"></span>
<img src="visuals/t-test-model-two-populations.png" alt="Graphical representation of the model underlying a frequentist two-population $t$-test (for unpaired data with equal variance and unequal sample sizes). Notice that the light shading of the node for the standard deviation indicates that the value for this parameter is estimated from the data." width="90%" />
<p class="caption">
Figure 16.16: Graphical representation of the model underlying a frequentist two-population <span class="math inline">\(t\)</span>-test (for unpaired data with equal variance and unequal sample sizes). Notice that the light shading of the node for the standard deviation indicates that the value for this parameter is estimated from the data.
</p>
</div>
<p>Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-t-test-model-two-populations">16.16</a> gives us the template to compute the value of the test statistic for the observed data:</p>
<div class="sourceCode" id="cb658"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb658-1" data-line-number="1"><span class="co"># fix the null hypothesis: no difference between groups</span></a>
<a class="sourceLine" id="cb658-2" data-line-number="2">delta_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb658-3" data-line-number="3"><span class="co"># data (group A)</span></a>
<a class="sourceLine" id="cb658-4" data-line-number="4">x_A &lt;-<span class="st"> </span>avocado_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb658-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(type <span class="op">==</span><span class="st"> &quot;organic&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(average_price)</a>
<a class="sourceLine" id="cb658-6" data-line-number="6"><span class="co"># data (group B)</span></a>
<a class="sourceLine" id="cb658-7" data-line-number="7">x_B &lt;-<span class="st"> </span>avocado_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb658-8" data-line-number="8"><span class="st">  </span><span class="kw">filter</span>(type <span class="op">==</span><span class="st"> &quot;conventional&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(average_price)</a>
<a class="sourceLine" id="cb658-9" data-line-number="9"><span class="co"># sample mean for organic (group A)</span></a>
<a class="sourceLine" id="cb658-10" data-line-number="10">mu_A &lt;-<span class="st"> </span><span class="kw">mean</span>(x_A)</a>
<a class="sourceLine" id="cb658-11" data-line-number="11"><span class="co"># sample mean for conventional (group B)</span></a>
<a class="sourceLine" id="cb658-12" data-line-number="12">mu_B &lt;-<span class="st"> </span><span class="kw">mean</span>(x_B)</a>
<a class="sourceLine" id="cb658-13" data-line-number="13"><span class="co"># numbers of observations</span></a>
<a class="sourceLine" id="cb658-14" data-line-number="14">n_A &lt;-<span class="st"> </span><span class="kw">length</span>(x_A)</a>
<a class="sourceLine" id="cb658-15" data-line-number="15">n_B &lt;-<span class="st"> </span><span class="kw">length</span>(x_B)</a>
<a class="sourceLine" id="cb658-16" data-line-number="16"><span class="co"># variance estimate</span></a>
<a class="sourceLine" id="cb658-17" data-line-number="17">sigma_AB &lt;-<span class="st"> </span><span class="kw">sqrt</span>(</a>
<a class="sourceLine" id="cb658-18" data-line-number="18">  ( ((n_A <span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(x_A)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(n_B <span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(x_B)<span class="op">^</span><span class="dv">2</span> ) <span class="op">/</span><span class="st"> </span></a>
<a class="sourceLine" id="cb658-19" data-line-number="19"><span class="st">      </span>(n_A <span class="op">+</span><span class="st"> </span>n_B <span class="dv">-2</span>) ) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n_A <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n_B)</a>
<a class="sourceLine" id="cb658-20" data-line-number="20">)</a>
<a class="sourceLine" id="cb658-21" data-line-number="21">t_observed &lt;-<span class="st"> </span>(mu_A <span class="op">-</span><span class="st"> </span>mu_B <span class="op">-</span><span class="st"> </span>delta_<span class="dv">0</span>) <span class="op">/</span><span class="st"> </span>sigma_AB</a>
<a class="sourceLine" id="cb658-22" data-line-number="22">t_observed  </a></code></pre></div>
<pre><code>## [1] 105.5878</code></pre>
<p>We can use the value of the test statistic for the observed data to compute a one-sided <span class="math inline">\(p\)</span>-value, as before. Notice that we use a one-sided test because we hypothesize that organically grown avocados are more expensive, not just that they have a different price (more expensive or cheaper).</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb660-1" data-line-number="1">p_value_t_test_avocado &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(<span class="dt">q =</span> t_observed, <span class="dt">df =</span> n_A <span class="op">+</span><span class="st"> </span>n_B <span class="op">-</span><span class="st"> </span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb660-2" data-line-number="2">p_value_t_test_avocado</a></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>Owing to number imprecision, the calculated <span class="math inline">\(p\)</span>-value comes up as a flat zero. We have a lot of data, and the task of defending that conventionally grown avocados are not less expensive than organically grown is very tough. This also shows in the corresponding picture in Figure <a href="ch-03-05-hypothesis-testing-tests.html#fig:ch-03-04-t-test-two-sample">16.17</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-04-t-test-two-sample"></span>
<img src="I2DA_files/figure-html/ch-03-04-t-test-two-sample-1.png" alt="Sampling distribution for a two-sample $t$-test, testing the null hypothesis of no difference between groups, based on the avocado data." width="90%" />
<p class="caption">
Figure 16.17: Sampling distribution for a two-sample <span class="math inline">\(t\)</span>-test, testing the null hypothesis of no difference between groups, based on the avocado data.
</p>
</div>
<p>We can also, of course, calculate this test result with the built-in function <code>t.test</code>:</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb662-1" data-line-number="1"><span class="kw">t.test</span>(</a>
<a class="sourceLine" id="cb662-2" data-line-number="2">  <span class="dt">x =</span> x_A,           <span class="co"># first vector of data measurements</span></a>
<a class="sourceLine" id="cb662-3" data-line-number="3">  <span class="dt">y =</span> x_B,           <span class="co"># second vector of data measurements</span></a>
<a class="sourceLine" id="cb662-4" data-line-number="4">  <span class="dt">paired =</span> <span class="ot">FALSE</span>,    <span class="co"># measurements are to be treated as unpaired</span></a>
<a class="sourceLine" id="cb662-5" data-line-number="5">  <span class="dt">var.equal =</span> <span class="ot">TRUE</span>,  <span class="co"># we assume equal variance in both groups</span></a>
<a class="sourceLine" id="cb662-6" data-line-number="6">  <span class="dt">mu =</span> <span class="dv">0</span>             <span class="co"># NH is delta = 0 (name &#39;mu&#39; is misleading!)</span></a>
<a class="sourceLine" id="cb662-7" data-line-number="7">)</a></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  x_A and x_B
## t = 105.59, df = 18247, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.4867522 0.5051658
## sample estimates:
## mean of x mean of y 
##  1.653999  1.158040</code></pre>
<p>The result could be reported as follows:</p>
<blockquote>
<p>We conducted a two-sample <span class="math inline">\(t\)</span>-test of differences of means (unpaired samples, equal variance, unequal sample sizes) to compare the average weekly price of conventionally grown avocados to that of organically grown avocados. The test result indicates a significant difference for the null hypothesis that conventionally grown avocados are not cheaper (<span class="math inline">\(N_A = 9123\)</span>, <span class="math inline">\(N_B = 9126\)</span>, <span class="math inline">\(t \approx 105.59\)</span>, <span class="math inline">\(p \approx 0\)</span>).</p>
</blockquote>
<!-- exercise 3 -->
<div class = "exercises">
<p><strong>Exercise 10.3: Two-sample <span class="math inline">\(t\)</span>-test</strong></p>
<p>Your fellow student is skeptical of her flatmate’s claim that pizzas from place <span class="math inline">\(A\)</span> have a smaller diameter than place <span class="math inline">\(B\)</span> (both pizzerias have just one pizza size, namely <span class="math inline">\(\varnothing\ 32\ cm\)</span>). She decides to test that claim with a two-sample <span class="math inline">\(t\)</span>-test and sets <span class="math inline">\(H_0: \mu_A = \mu_B\)</span> (<span class="math inline">\(\delta = 0\)</span>), <span class="math inline">\(H_a: \mu_A &lt; \mu_B\)</span>, <span class="math inline">\(\alpha = 0.05\)</span>. She then asks your class to always measure the pizza’s diameter if ordered from one of the two places. At the end of the semester, she has the following table:</p>
<div align="center">

<table style='width:70%'>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Pizzeria <span class="math inline">\(A\)</span>
</th>
<th style="text-align:center;">
Pizzeria <span class="math inline">\(B\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
mean
</td>
<td style="text-align:center;">
30.9
</td>
<td style="text-align:center;">
31.8
</td>
</tr>
<tr>
<td style="text-align:center;">
standard deviation
</td>
<td style="text-align:center;">
2.3
</td>
<td style="text-align:center;">
2
</td>
</tr>
<tr>
<td style="text-align:center;">
sample size
</td>
<td style="text-align:center;">
38
</td>
<td style="text-align:center;">
44
</td>
</tr>
</tbody>
</table>
</div>
<ol style="list-style-type: lower-alpha">
<li>How many degrees of freedom <span class="math inline">\(\nu\)</span> are there?</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p><span class="math inline">\(\nu = n_A+n_B-2 = 38+44-2 = 80\)</span> degrees of freedom.</p>
</div>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Given the table above, calculate the test statistic <span class="math inline">\(t\)</span>.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p><span class="math display">\[
\hat{\sigma}=\sqrt{\frac{(n_A-1)\hat{\sigma}_A^2+(n_B-1)\hat{\sigma}^2_B}{n_A+n_B-2}(\frac{1}{n_A}+\frac{1}{n_B})}\\
\hat{\sigma}=\sqrt{\frac{37\cdot2.3^2+43\cdot2^2}{80}(\frac{1}{38}+\frac{1}{44})}\approx 0.47\\
t=((\bar{x}_A-\bar{x}_B)-\delta)\cdot\frac{1}{\hat{\sigma}}\\
t=\frac{30.9-31.8}{0.47}\approx -1.91
\]</span></p>
</div>
</div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Look at this so-called <a href="http://www.ttable.org/">t table</a> and determine the critical value to be exceeded in order to get a statistically significant result. NB: We are looking for the critical value that is on the <em>left</em> side of the distribution. So, in order to have a statistically significant result, the test statistic from b. has to be smaller than the <em>negated</em> critical value in the table.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>The critical value is -1.664.</p>
</div>
</div>
<ol start="4" style="list-style-type: lower-alpha">
<li>Compare the test statistic from b. with the critical value from c. and interpret the result.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>The calculated test statistic from b. is smaller than the critical value. We therefore know that the <span class="math inline">\(p\)</span>-value is statistically significant. The fellow student should reject the null hypothesis of equal pizza diameters.</p>
</div>
</div>
</div>
</div>
</div>
<div id="ch-03-05-hypothesis-testing-ANOVA" class="section level3">
<h3><span class="header-section-number">16.3.4</span> ANOVA</h3>
<p>We have <span class="math inline">\(k\)</span> groups of metric observations. For group <span class="math inline">\(1 \le j \le k\)</span>, there are <span class="math inline">\(n_j\)</span> observations. Let <span class="math inline">\(x_{ij}\)</span> be the observation <span class="math inline">\(1 \le i \le n_j\)</span> for group <span class="math inline">\(1 \le j \le k\)</span>. Let <span class="math inline">\(\bar{x}_j = \frac{1}{n} \sum_{i = 1}^{n_j} x_{ij}\)</span> be the mean of group <span class="math inline">\(j\)</span> and let <span class="math inline">\(\bar{\bar{x}} = \frac{1}{k} \sum_{j=1}^k \frac{1}{n_j} \sum_{i=1}^{n_j} x_{ij}\)</span> be the grand mean of all data points. We would like to show that the total sum of squares can be decomposed into two summands: the within-group sum of squares and the between-group sum of squares:</p>
<p><span class="math display">\[ 
\underbrace{
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{\bar{x}})^2
}_{\text{Total SS}}  = 
\underbrace{
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)^2
}_{\text{Within-Group SS}} +
\underbrace{
  \sum_{j=1}^k n_j (\bar{x}_j - \bar{\bar{x}})^2
}_{\text{Between-Group SS}}
\]</span></p>
<p>To show this, we first establish a lemma, which will also be useful later:</p>

<div class="lemma">
<span id="lem:SS-cancellation" class="lemma"><strong>Lemma 16.1  (Sum of squares cancellation)  </strong></span>Let <span class="math inline">\(\vec{x}\)</span> be a vector of <span class="math inline">\(n\)</span> real-valued numbers, and let <span class="math inline">\(\bar{x} = \frac{1}{n} \sum_{i=i}^n x_i\)</span> be its mean. The sum of squares around the mean is zero:
<span class="math display">\[
  \sum_{i=1}^n (x_i - \bar{x}) = 0
\]</span>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <span class="math display">\[
\begin{aligned}
  \sum_{i=i}^n (x_i - \bar{x}) 
  &amp; = 
  \sum_{i=i}^n (x_i - \frac{1}{n} \sum_{j=1}^n x_j) 
  &amp;&amp; 
  [\text{by def. of mean}] 
  \\
  &amp; = 
  \sum_{i=i}^n x_i - \frac{n}{n} \sum_{j=1}^n x_j) 
  &amp;&amp; 
  [\text{second summand independent of } i] 
  \\ 
  &amp; = 0
  \\ 
\end{aligned}
\]</span>
</div>

<p> </p>

<div class="proposition">
<span id="prp:ANOVA-SS-decomposition" class="proposition"><strong>Proposition 16.1  (Sum of squares decomposition (ANOVA))  </strong></span>If <span class="math inline">\(x_{ij}\)</span> is observation <span class="math inline">\(1 \le i \le n_j\)</span> for group <span class="math inline">\(1 \le j \le k\)</span>, <span class="math inline">\(\bar{x}_j = \frac{1}{n} \sum_{i = 1}^{n_j} x_{ij}\)</span> the mean of group <span class="math inline">\(j\)</span> and <span class="math inline">\(\bar{\bar{x}} = \frac{1}{k} \sum_{j=1}^k \frac{1}{n_j} \sum_{i=1}^{n_j} x_{ij}\)</span> be the grand mean of all data points, then:
<span class="math display">\[ 
\underbrace{
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{\bar{x}})^2
}_{\text{Total SS}}  = 
\underbrace{
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)^2
}_{\text{Within-Group SS}} +
\underbrace{
  \sum_{j=1}^k n_j (\bar{x}_j - \bar{\bar{x}})^2
}_{\text{Between-Group SS}}
\]</span>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <span class="math display">\[
\begin{aligned}
  &amp; 
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{\bar{x}})^2 
  \\
  = &amp;  
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j + \bar{x}_j - \bar{\bar{x}})^2
  &amp;&amp; 
  [- \bar{x}_j + \bar{x}_j = 0] 
  \\
  = &amp;  
  \sum_{j=1}^k \sum_{i=1}^{n_j} \left [ (x_{ij} - \bar{x}_j)^2 + 2(x_{ij} - \bar{x}_j)(\bar{x}_j - \bar{\bar{x}}) + (\bar{x}_j - \bar{\bar{x}})^2 \right ]
  &amp;&amp; 
  [\text{binomial theorem}] 
  \\
  = &amp;  
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)^2 + 
  \sum_{j=1}^k \sum_{i=1}^{n_j} (\bar{x}_j - \bar{\bar{x}})^2 + 
  \sum_{j=1}^k \sum_{i=1}^{n_j} 2(x_{ij} - \bar{x}_j)(\bar{x}_j - \bar{\bar{x}})
  &amp;&amp; 
  [\text{rearranging} ] 
  \\
  = &amp;  
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)^2 + 
  \sum_{j=1}^k n_j (\bar{x}_j - \bar{\bar{x}})^2 + 
  2 \sum_{j=1}^k (\bar{x}_j - \bar{\bar{x}}) \underbrace{\sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)}_{\text{=0 by lemma}}
  &amp;&amp; 
  [\text{independences} ] 
  \\
    = &amp;  
  \sum_{j=1}^k \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)^2 + 
  \sum_{j=1}^k n_j (\bar{x}_j - \bar{\bar{x}})^2
  &amp;&amp; 
  [\text{by lemma} ] 
\end{aligned}
\]</span>
</div>

<p> </p>
<p><img src="I2DA_files/figure-html/unnamed-chunk-458-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb664-1" data-line-number="1"><span class="co"># fictitious data</span></a>
<a class="sourceLine" id="cb664-2" data-line-number="2">x_A &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">78</span>, <span class="dv">43</span>, <span class="dv">60</span>, <span class="dv">60</span>, <span class="dv">60</span>, <span class="dv">50</span>, <span class="dv">57</span>, <span class="dv">58</span>, <span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">56</span>, <span class="dv">62</span>, <span class="dv">66</span>, <span class="dv">53</span>, <span class="dv">59</span>)</a>
<a class="sourceLine" id="cb664-3" data-line-number="3">x_B &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">52</span>, <span class="dv">53</span>, <span class="dv">51</span>, <span class="dv">49</span>, <span class="dv">64</span>, <span class="dv">60</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">55</span>, <span class="dv">65</span>, <span class="dv">76</span>, <span class="dv">62</span>, <span class="dv">62</span>, <span class="dv">45</span>)</a>
<a class="sourceLine" id="cb664-4" data-line-number="4">x_C &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">78</span>, <span class="dv">66</span>, <span class="dv">74</span>, <span class="dv">57</span>, <span class="dv">75</span>, <span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">53</span>, <span class="dv">63</span>, <span class="dv">60</span>, <span class="dv">79</span>, <span class="dv">68</span>, <span class="dv">68</span>, <span class="dv">47</span>, <span class="dv">63</span>, <span class="dv">67</span>)</a>
<a class="sourceLine" id="cb664-5" data-line-number="5"><span class="co"># number of observations in each group</span></a>
<a class="sourceLine" id="cb664-6" data-line-number="6">n_A &lt;-<span class="st"> </span><span class="kw">length</span>(x_A)</a>
<a class="sourceLine" id="cb664-7" data-line-number="7">n_B &lt;-<span class="st"> </span><span class="kw">length</span>(x_B) </a>
<a class="sourceLine" id="cb664-8" data-line-number="8">n_C &lt;-<span class="st"> </span><span class="kw">length</span>(x_C)</a>
<a class="sourceLine" id="cb664-9" data-line-number="9"><span class="co"># in tibble form</span></a>
<a class="sourceLine" id="cb664-10" data-line-number="10">anova_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb664-11" data-line-number="11">  <span class="dt">condition =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb664-12" data-line-number="12">    <span class="kw">rep</span>(<span class="st">&quot;A&quot;</span>, n_A),</a>
<a class="sourceLine" id="cb664-13" data-line-number="13">    <span class="kw">rep</span>(<span class="st">&quot;B&quot;</span>, n_B),</a>
<a class="sourceLine" id="cb664-14" data-line-number="14">    <span class="kw">rep</span>(<span class="st">&quot;C&quot;</span>, n_C)</a>
<a class="sourceLine" id="cb664-15" data-line-number="15">    ),</a>
<a class="sourceLine" id="cb664-16" data-line-number="16">  <span class="dt">value =</span> <span class="kw">c</span>(x_A, x_B, x_C)</a>
<a class="sourceLine" id="cb664-17" data-line-number="17">)</a>
<a class="sourceLine" id="cb664-18" data-line-number="18"></a>
<a class="sourceLine" id="cb664-19" data-line-number="19">anova_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb664-20" data-line-number="20"><span class="st">  </span><span class="kw">ggplot</span>(</a>
<a class="sourceLine" id="cb664-21" data-line-number="21">      <span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> value, <span class="dt">color =</span> condition)</a>
<a class="sourceLine" id="cb664-22" data-line-number="22">    ) <span class="op">+</span></a>
<a class="sourceLine" id="cb664-23" data-line-number="23"><span class="st">    </span><span class="kw">geom_point</span>(</a>
<a class="sourceLine" id="cb664-24" data-line-number="24">      <span class="dt">fill =</span> <span class="st">&quot;lightgray&quot;</span>,</a>
<a class="sourceLine" id="cb664-25" data-line-number="25">      <span class="dt">size =</span><span class="fl">1.5</span>,</a>
<a class="sourceLine" id="cb664-26" data-line-number="26">      <span class="dt">alpha =</span> <span class="fl">0.4</span></a>
<a class="sourceLine" id="cb664-27" data-line-number="27">    ) <span class="op">+</span></a>
<a class="sourceLine" id="cb664-28" data-line-number="28"><span class="st">    </span><span class="kw">guides</span>(<span class="dt">color =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb664-29" data-line-number="29"><span class="st">    </span><span class="kw">geom_segment</span>(<span class="dt">size =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb664-30" data-line-number="30">      <span class="kw">aes</span>(</a>
<a class="sourceLine" id="cb664-31" data-line-number="31">        <span class="dt">x =</span> condition_number <span class="op">-</span><span class="st"> </span><span class="fl">0.3</span>,</a>
<a class="sourceLine" id="cb664-32" data-line-number="32">        <span class="dt">xend =</span> condition_number <span class="op">+</span><span class="st"> </span><span class="fl">0.3</span>,</a>
<a class="sourceLine" id="cb664-33" data-line-number="33">        <span class="dt">y =</span> condition_mean,</a>
<a class="sourceLine" id="cb664-34" data-line-number="34">        <span class="dt">yend =</span> condition_mean</a>
<a class="sourceLine" id="cb664-35" data-line-number="35">      ),</a>
<a class="sourceLine" id="cb664-36" data-line-number="36">      <span class="dt">data =</span> anova_data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(condition) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb664-37" data-line-number="37"><span class="st">        </span><span class="kw">summarise</span>(<span class="dt">condition_mean =</span> <span class="kw">mean</span>(value)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb664-38" data-line-number="38"><span class="st">        </span><span class="kw">mutate</span>(<span class="dt">condition_number =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb664-39" data-line-number="39">    ) <span class="op">+</span></a>
<a class="sourceLine" id="cb664-40" data-line-number="40"><span class="st">    </span><span class="kw">labs</span>(</a>
<a class="sourceLine" id="cb664-41" data-line-number="41">      <span class="dt">x =</span> <span class="st">&quot;&quot;</span>,</a>
<a class="sourceLine" id="cb664-42" data-line-number="42">      <span class="dt">y =</span> <span class="st">&quot;&quot;</span></a>
<a class="sourceLine" id="cb664-43" data-line-number="43">    )</a></code></pre></div>
<p><img src="I2DA_files/figure-html/unnamed-chunk-459-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb665"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb665-1" data-line-number="1">grand_mean &lt;-<span class="st"> </span>anova_data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(value) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mean</span>()</a>
<a class="sourceLine" id="cb665-2" data-line-number="2">df1 &lt;-<span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb665-3" data-line-number="3">df2 &lt;-<span class="st"> </span>n_A <span class="op">+</span><span class="st"> </span>n_B <span class="op">+</span><span class="st"> </span>n_C <span class="dv">-3</span></a>
<a class="sourceLine" id="cb665-4" data-line-number="4"></a>
<a class="sourceLine" id="cb665-5" data-line-number="5"><span class="co"># between-group sum-of-squares</span></a>
<a class="sourceLine" id="cb665-6" data-line-number="6">between_group_variance &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>df1 <span class="op">*</span></a>
<a class="sourceLine" id="cb665-7" data-line-number="7"><span class="st">  </span>(</a>
<a class="sourceLine" id="cb665-8" data-line-number="8">    n_A <span class="op">*</span><span class="st"> </span>(<span class="kw">mean</span>(x_A) <span class="op">-</span><span class="st"> </span>grand_mean)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span></a>
<a class="sourceLine" id="cb665-9" data-line-number="9"><span class="st">    </span>n_B <span class="op">*</span><span class="st"> </span>(<span class="kw">mean</span>(x_B) <span class="op">-</span><span class="st"> </span>grand_mean)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span></a>
<a class="sourceLine" id="cb665-10" data-line-number="10"><span class="st">    </span>n_C <span class="op">*</span><span class="st"> </span>(<span class="kw">mean</span>(x_C) <span class="op">-</span><span class="st"> </span>grand_mean)<span class="op">^</span><span class="dv">2</span>  </a>
<a class="sourceLine" id="cb665-11" data-line-number="11">  )</a>
<a class="sourceLine" id="cb665-12" data-line-number="12">  </a>
<a class="sourceLine" id="cb665-13" data-line-number="13"><span class="co"># within-group sum-of-squares</span></a>
<a class="sourceLine" id="cb665-14" data-line-number="14">within_group_variance &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>df2 <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb665-15" data-line-number="15"><span class="st">  </span>(</a>
<a class="sourceLine" id="cb665-16" data-line-number="16">    <span class="kw">sum</span>((x_A <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x_A))<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb665-17" data-line-number="17"><span class="st">    </span><span class="kw">sum</span>((x_B <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x_B))<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb665-18" data-line-number="18"><span class="st">    </span><span class="kw">sum</span>((x_C <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x_C))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb665-19" data-line-number="19">  )</a>
<a class="sourceLine" id="cb665-20" data-line-number="20"><span class="co"># test statistic of observed data</span></a>
<a class="sourceLine" id="cb665-21" data-line-number="21">F_observed &lt;-<span class="st">  </span>between_group_variance <span class="op">/</span><span class="st"> </span>within_group_variance</a></code></pre></div>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb666-1" data-line-number="1">p_value_anova &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>(F_observed, <span class="dv">2</span>, n_A <span class="op">+</span><span class="st"> </span>n_B <span class="op">+</span><span class="st"> </span>n_C <span class="dv">-3</span>)</a>
<a class="sourceLine" id="cb666-2" data-line-number="2">p_value_anova <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">4</span>)</a></code></pre></div>
<pre><code>## [1] 0.0172</code></pre>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb668-1" data-line-number="1"><span class="kw">aov</span>(<span class="dt">formula =</span> value <span class="op">~</span><span class="st"> </span>condition, anova_data) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## condition    2  640.8   320.4   4.485 0.0172 *
## Residuals   42 3000.3    71.4                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<p>Based on a one-way ANOVA, we find evidence against the assumption of equal means across all groups (<span class="math inline">\(F(2, 42) \approx 4.485\)</span>, <span class="math inline">\(p \approx 0.0172\)</span>).</p>
</blockquote>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="84">
<li id="fn84"><p>Notice that for economy or presentation, we now (again) gloss over the “raw” data of individual choices and present the summarized count data instead. In the previous case of the Binomial Test, it made good pedagogical sense to tease apart the “raw” observations from the summarized counts because this helped to show what the test statistic is for a case, where the choice of it was very, very obvious; so much so, that we would normally not even bother to make it explicit. Now that we understood what a test statistic is in principle, we can gloss over some steps of data summarizing.<a href="ch-03-05-hypothesis-testing-tests.html#fnref84" class="footnote-back">↩</a></p></li>
<li id="fn85"><p>A proof of this fact is non-trivial, but an intuition why this might be so is available if we think of each cell independently first. In each cell, with more and more samples, the distribution of counts will approximate a normal distribution by the CLT. The <span class="math inline">\(\chi^2\)</span>-distribution rests (by construction) on a sum of squared samples from a standard normal distribution.<a href="ch-03-05-hypothesis-testing-tests.html#fnref85" class="footnote-back">↩</a></p></li>
<li id="fn86"><p>Notice that this is a one-sided test due to the nature of the test statistic, which measures squared deviation from the baseline and not deviation in any particular direction (because it is hard to say what a “direction” would be in this case anyway).<a href="ch-03-05-hypothesis-testing-tests.html#fnref86" class="footnote-back">↩</a></p></li>
<li id="fn87"><p>Notice that the original avocado data set contains information also about the place of measurement, which would in principle allow us to treat the price measurements as paired samples (one pair for each week and place). For simplicity, but with a note of care that this makes us lose possibly relevant structural information, we here treat the avocado data as if it contained unpaired samples.<a href="ch-03-05-hypothesis-testing-tests.html#fnref87" class="footnote-back">↩</a></p></li>
<li id="fn88"><p>This is intuitively so because the test statistic is concerned only with the difference between sample means.<a href="ch-03-05-hypothesis-testing-tests.html#fnref88" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-03-05-hypothesis-testing-CLT.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-03-05-hypothesis-testing-3-approaches.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["I2DA.epub", "I2DA.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
